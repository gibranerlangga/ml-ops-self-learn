{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313a21a7-3ebf-421f-9e04-2d7cb65f5496",
   "metadata": {},
   "source": [
    "# Penguins Pipeline in Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73402792-38fb-4c98-9d1e-081239f65fae",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook aims to create a [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) to build an end-to-end Machine Learning system to solve the problem of classifying penguin species based on the [Penguins dataset](https://www.kaggle.com/datasets/parulpandey/palmer-archipelago-antarctica-penguin-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89a041-d459-426f-a493-408d1799eafd",
   "metadata": {},
   "source": [
    "### Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e413bf-fea9-4a8f-bb80-5a76305acd0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.4.2 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.161 which is incompatible.\n",
      "sagemaker 2.165.0 requires importlib-metadata<5.0,>=1.4.0, but you have importlib-metadata 6.6.0 which is incompatible.\n",
      "sagemaker 2.165.0 requires PyYAML==6.0, but you have pyyaml 5.4.1 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.161 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "sagemaker 2.165.0 requires importlib-metadata<5.0,>=1.4.0, but you have importlib-metadata 6.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "python-language-server 0.31.7 requires jedi<0.16,>=0.14.1, but you have jedi 0.18.2 which is incompatible.\n",
      "python-language-server 0.31.7 requires ujson<=1.35; platform_system != \"Windows\", but you have ujson 5.7.0 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\n",
      "spyder 4.0.1 requires jedi==0.14.1, but you have jedi 0.18.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mName: sagemaker\n",
      "Version: 2.165.0\n",
      "Summary: Open source library for training and deploying models on Amazon SageMaker.\n",
      "Home-page: https://github.com/aws/sagemaker-python-sdk/\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: /opt/conda/lib/python3.7/site-packages\n",
      "Requires: attrs, boto3, cloudpickle, google-pasta, importlib-metadata, jsonschema, numpy, packaging, pandas, pathos, platformdirs, protobuf, protobuf3-to-dict, PyYAML, schema, smdebug-rulesconfig, tblib\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade pip\n",
    "!pip install -q --upgrade awscli boto3\n",
    "!pip install -q --upgrade scikit-learn==0.23.2\n",
    "!pip install -q --upgrade PyYAML==6.0\n",
    "!pip install -q --upgrade sagemaker==2.165.0\n",
    "!pip show sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21be329-e4a1-447f-ac17-ce3235b66512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dcaf8e-ed48-423d-bedc-5a40e42635d0",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72d74b7a-e55c-4cc4-a026-e61523a8cc15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Location\": \"/mlschool-gibran-2023\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "BUCKET = \"mlschool-gibran-2023\"\n",
    "\n",
    "!aws s3api create-bucket --bucket $BUCKET --region us-east-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82fec4f3-e7f4-49b8-9c7a-4cbcc98260e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset S3 location: s3://mlschool-gibran-2023/penguins/data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sagemaker\n",
    "import urllib.request\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "PENGUINS_FOLDER = Path(\"penguins\")\n",
    "S3_FILEPATH = f\"s3://{BUCKET}/{PENGUINS_FOLDER}\"\n",
    "LOCAL_FILEPATH = Path(PENGUINS_FOLDER)/ \"data.csv\"\n",
    "\n",
    "# Create the local folder if it doesn't exist.\n",
    "PENGUINS_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the official Penguins dataset and store it locally.\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins_size.csv\", \n",
    "    LOCAL_FILEPATH\n",
    ")\n",
    "\n",
    "# Upload the dataset to S3. We need to do this to make it available to \n",
    "# the preprocessing step.\n",
    "INPUT_DATA_URI = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=str(LOCAL_FILEPATH), \n",
    "    desired_s3_uri=S3_FILEPATH,\n",
    ")\n",
    "\n",
    "print(f\"Dataset S3 location: {INPUT_DATA_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bb6849b-07c1-430a-8362-fd31c80f0da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0    Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1    Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2    Adelie  Torgersen              40.3             18.0              195.0   \n",
       "3    Adelie  Torgersen               NaN              NaN                NaN   \n",
       "4    Adelie  Torgersen              36.7             19.3              193.0   \n",
       "..      ...        ...               ...              ...                ...   \n",
       "339  Gentoo     Biscoe               NaN              NaN                NaN   \n",
       "340  Gentoo     Biscoe              46.8             14.3              215.0   \n",
       "341  Gentoo     Biscoe              50.4             15.7              222.0   \n",
       "342  Gentoo     Biscoe              45.2             14.8              212.0   \n",
       "343  Gentoo     Biscoe              49.9             16.1              213.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "0         3750.0    MALE  \n",
       "1         3800.0  FEMALE  \n",
       "2         3250.0  FEMALE  \n",
       "3            NaN     NaN  \n",
       "4         3450.0  FEMALE  \n",
       "..           ...     ...  \n",
       "339          NaN     NaN  \n",
       "340       4850.0  FEMALE  \n",
       "341       5750.0    MALE  \n",
       "342       5200.0  FEMALE  \n",
       "343       5400.0    MALE  \n",
       "\n",
       "[344 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(LOCAL_FILEPATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f798c06-e929-410b-ab2f-4d62eade9906",
   "metadata": {},
   "source": [
    "# Session 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec4d19b1-4f5e-43ab-b938-eac9921eb5c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import argparse\n",
    "import tempfile\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import CacheConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "181ad1e0-c546-4b80-ab90-0f992cc71a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iam_client = boto3.client(\"iam\")\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd67c7da-0d56-4911-8515-98999f3c5f8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1 - Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8035fee3-b74f-489e-b7dd-5e1ab671e158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguins/preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PENGUINS_FOLDER}/preprocessor.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from pickle import dump\n",
    "\n",
    "\n",
    "# This is the location where the SageMaker Processing job\n",
    "# will save the input dataset.\n",
    "BASE_DIRECTORY = \"/opt/ml/processing\"\n",
    "DATA_FILEPATH = Path(BASE_DIRECTORY) / \"input\" / \"data.csv\"\n",
    "\n",
    "\n",
    "def _save_splits(base_directory, train, validation, test):\n",
    "    \"\"\"\n",
    "    One of the goals of this script is to output the three\n",
    "    dataset splits. This function will save each of these\n",
    "    splits to disk.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_path = Path(base_directory) / \"train\" \n",
    "    validation_path = Path(base_directory) / \"validation\" \n",
    "    test_path = Path(base_directory) / \"test\"\n",
    "    \n",
    "    train_path.mkdir(parents=True, exist_ok=True)\n",
    "    validation_path.mkdir(parents=True, exist_ok=True)\n",
    "    test_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    pd.DataFrame(train).to_csv(train_path / \"train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(validation_path / \"validation.csv\", header=False, index=False)\n",
    "    pd.DataFrame(test).to_csv(test_path / \"test.csv\", header=False, index=False)\n",
    "    \n",
    "\n",
    "def _save_pipeline(base_directory, pipeline):\n",
    "    \"\"\"\n",
    "    Saves the Scikit-Learn pipeline that we used to\n",
    "    preprocess the data.\n",
    "    \"\"\"\n",
    "    pipeline_path = Path(base_directory) / \"pipeline\"\n",
    "    pipeline_path.mkdir(parents=True, exist_ok=True)\n",
    "    dump(pipeline, open(pipeline_path / \"pipeline.pkl\", 'wb'))\n",
    "    \n",
    "\n",
    "def _save_classes(base_directory, classes):\n",
    "    \"\"\"\n",
    "    Saves the list of classes from the dataset.\n",
    "    \"\"\"\n",
    "    path = Path(base_directory) / \"classes\"\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"CLASSES\", np.asarray(classes))\n",
    "\n",
    "    np.asarray(classes).tofile(path / \"classes.csv\", sep = \",\") \n",
    "    \n",
    "\n",
    "def _generate_baseline_dataset(split_name, base_directory, X, y):\n",
    "    \"\"\"\n",
    "    To monitor the data and the quality of our model we need to compare the \n",
    "    production quality and results against a baseline. To create those baselines, \n",
    "    we need to use a dataset to compute statistics and constraints. That dataset\n",
    "    should contain information in the same format as expected by the production\n",
    "    endpoint. This function will generate a baseline dataset and save it to \n",
    "    disk so we can later use it.\n",
    "    \n",
    "    \"\"\"\n",
    "    baseline_path = Path(base_directory) / f\"{split_name}-baseline\" \n",
    "    baseline_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = X.copy()\n",
    "    \n",
    "    # The baseline dataset needs a column containing the groundtruth.\n",
    "    df[\"groundtruth\"] = y\n",
    "    df[\"groundtruth\"] = df[\"groundtruth\"].values.astype(str)\n",
    "    \n",
    "    # We will use the baseline dataset to generate baselines\n",
    "    # for monitoring data and model quality. To simplify the process, \n",
    "    # we don't want to include any NaN rows.\n",
    "    df = df.dropna()\n",
    "\n",
    "    df.to_json(baseline_path / f\"{split_name}-baseline.json\", orient='records', lines=True)\n",
    "    \n",
    "    \n",
    "def preprocess(base_directory, data_filepath):\n",
    "    \"\"\"\n",
    "    Preprocesses the supplied raw dataset and splits it into a train, validation,\n",
    "    and a test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(data_filepath)\n",
    "    \n",
    "    numerical_columns = [column for column in df.columns if df[column].dtype in [\"int64\", \"float64\"]]\n",
    "    \n",
    "    numerical_preprocessor = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_preprocessor = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"numerical\", numerical_preprocessor, numerical_columns),\n",
    "            (\"categorical\", categorical_preprocessor, [\"island\"]),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "    X = df.drop([\"sex\"], axis=1)\n",
    "    columns = list(X.columns)\n",
    "    \n",
    "    X = X.to_numpy()\n",
    "    \n",
    "    np.random.shuffle(X)\n",
    "    train, validation, test = np.split(X, [int(.7 * len(X)), int(.85 * len(X))])\n",
    "    \n",
    "    X_train = pd.DataFrame(train, columns=columns)\n",
    "    X_validation = pd.DataFrame(validation, columns=columns)\n",
    "    X_test = pd.DataFrame(test, columns=columns)\n",
    "    \n",
    "    y_train = X_train.species\n",
    "    y_validation = X_validation.species\n",
    "    y_test = X_test.species\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_validation = label_encoder.transform(y_validation)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "    \n",
    "    X_train.drop([\"species\"], axis=1, inplace=True)\n",
    "    X_validation.drop([\"species\"], axis=1, inplace=True)\n",
    "    X_test.drop([\"species\"], axis=1, inplace=True)\n",
    "\n",
    "    # Let's generate a dataset that we can later use to compute\n",
    "    # baseline statistics and constraints about the data that we\n",
    "    # used to train our model.\n",
    "    _generate_baseline_dataset(\"train\", base_directory, X_train, y_train)\n",
    "    \n",
    "    # To generate baseline constraints about the quality of the\n",
    "    # model's predictions, we will use the test set.\n",
    "    _generate_baseline_dataset(\"test\", base_directory, X_test, y_test)\n",
    "    \n",
    "    # Transform the data using the Scikit-Learn pipeline.\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    X_validation = preprocessor.transform(X_validation)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "    \n",
    "    train = np.concatenate((X_train, np.expand_dims(y_train, axis=1)), axis=1)\n",
    "    validation = np.concatenate((X_validation, np.expand_dims(y_validation, axis=1)), axis=1)\n",
    "    test = np.concatenate((X_test, np.expand_dims(y_test, axis=1)), axis=1)\n",
    "    \n",
    "    _save_splits(base_directory, train, validation, test)\n",
    "    _save_pipeline(base_directory, pipeline=preprocessor)\n",
    "    _save_classes(base_directory, label_encoder.classes_)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess(BASE_DIRECTORY, DATA_FILEPATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b73f4-e44a-456f-854c-723c84cc1b21",
   "metadata": {},
   "source": [
    "## Step 2 - Testing the Preprocessing Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7a50c46-0839-42eb-af75-1c1a8b4b74aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSES ['Adelie' 'Chinstrap' 'Gentoo']\n",
      "Folders: ['train-baseline', 'test-baseline', 'train', 'validation', 'test', 'pipeline', 'classes']\n"
     ]
    }
   ],
   "source": [
    "from penguins.preprocessor import preprocess\n",
    "\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    preprocess(\n",
    "        base_directory=directory, \n",
    "        data_filepath=LOCAL_FILEPATH\n",
    "    )\n",
    "    \n",
    "    print(f\"Folders: {os.listdir(directory)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4cf234-8b4e-4458-9996-397237f4e260",
   "metadata": {},
   "source": [
    "## Step 3 - Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5464c2dc-a3f0-4988-87bf-d8486f3ae3de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_location = ParameterString(\n",
    "    name=\"dataset_location\",\n",
    "    default_value=INPUT_DATA_URI,\n",
    ")\n",
    "\n",
    "preprocessor_destination = ParameterString(\n",
    "    name=\"preprocessor_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing\",\n",
    ")\n",
    "\n",
    "train_dataset_baseline_destination = ParameterString(\n",
    "    name=\"train_dataset_baseline_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing/baselines/train\",\n",
    ")\n",
    "\n",
    "test_dataset_baseline_destination = ParameterString(\n",
    "    name=\"test_dataset_baseline_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing/baselines/test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc7028-fdc6-47eb-8924-3bfb0c4fad21",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4 - Caching Pipeline Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14339439-8718-49f8-8336-bca92bb4c8fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_config = CacheConfig(\n",
    "    enable_caching=True, \n",
    "    expire_after=\"15d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ed5c6-2ac9-461b-96aa-70d536a6ee19",
   "metadata": {},
   "source": [
    "## Step 5 - Setting up a Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e743f41-523e-417c-ad8b-6a3f9b76bc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    base_job_name=\"penguins-preprocessing\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "preprocess_data_step = ProcessingStep(\n",
    "    name=\"preprocess-data\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=dataset_location, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"pipeline\", source=\"/opt/ml/processing/pipeline\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"classes\", source=\"/opt/ml/processing/classes\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"train-baseline\", source=\"/opt/ml/processing/train-baseline\", destination=train_dataset_baseline_destination),\n",
    "        ProcessingOutput(output_name=\"test-baseline\", source=\"/opt/ml/processing/test-baseline\", destination=test_dataset_baseline_destination),\n",
    "    ],\n",
    "    code=f\"{PENGUINS_FOLDER}/preprocessor.py\",\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091ba78-156f-4cd4-9cf5-5a561285f61f",
   "metadata": {},
   "source": [
    "## Step 6 - Running the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f02598de-441f-477c-8285-1aa0037d1b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session1_pipeline = Pipeline(\n",
    "    name=\"penguins-session1-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        train_dataset_baseline_destination,\n",
    "        test_dataset_baseline_destination\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_data_step, \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6cabecb-1394-4e0e-a561-e28c95babc32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session1_pipeline.upsert(role_arn=role)\n",
    "execution = session1_pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
