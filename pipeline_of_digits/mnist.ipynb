{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd2fdf97-bbc6-4973-bdde-db769f3b2585",
   "metadata": {},
   "source": [
    "# Pipeline of Digits\n",
    "\n",
    "This is a starting notebook for solving the \"Pipeline of Digits\" assignment.\n",
    "\n",
    "\n",
    "This notebook was created by [Santiago L. Valdarrama](https://twitter.com/svpino) as part of the [Machine Learning School](https://www.ml.school) program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae06bac-01d0-477e-b9f8-1fdd3ebf3dc7",
   "metadata": {},
   "source": [
    "Let's make sure we are running the latest version of the SakeMaker's SDK. **Restart the notebook** after you upgrade the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "505a53a1-babe-4238-ad19-e401a9f0a4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.29.1 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mName: sagemaker\n",
      "Version: 2.165.0\n",
      "Summary: Open source library for training and deploying models on Amazon SageMaker.\n",
      "Home-page: https://github.com/aws/sagemaker-python-sdk/\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: /usr/local/lib/python3.8/site-packages\n",
      "Requires: attrs, boto3, cloudpickle, google-pasta, importlib-metadata, jsonschema, numpy, packaging, pandas, pathos, platformdirs, protobuf, protobuf3-to-dict, PyYAML, schema, smdebug-rulesconfig, tblib\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade pip\n",
    "!pip install -q --upgrade awscli boto3\n",
    "!pip install -q --upgrade PyYAML==6.0\n",
    "!pip install -q --upgrade sagemaker==2.165.0\n",
    "!pip show sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8736d294-1434-4739-82a3-d0e7414a41bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96a6d2-3cd1-49ca-8219-8929c93b741d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98619548-6458-4ebd-afcb-547bd2488dae",
   "metadata": {},
   "source": [
    "## Creating the S3 Bucket\n",
    "\n",
    "Let's create an S3 bucket where you will upload all the information generated by the pipeline. Make sure you set `BUCKET` to the name of the bucket you want to use. This name has to be unique.\n",
    "\n",
    "If you want to create a bucket in a region other than `us-east-1`, use this command instead:\n",
    "\n",
    "```\n",
    "!aws s3api create-bucket --bucket $BUCKET --create-bucket-configuration LocationConstraint=$region\n",
    "```\n",
    "\n",
    "The `LocationConstraint` argument should specify the region where you want to create the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee4d0e-d3a6-4ac3-bd60-e04dd7028ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET = \"ml-school-gibran-2023-mnist\"\n",
    "\n",
    "# !aws s3api create-bucket --bucket $BUCKET --region us-east-2 --create-bucket-configuration LocationConstraint=us-east-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580ab4f-7a15-495d-9fbd-cacb546c9536",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the dataset\n",
    "\n",
    "We have two CSV files containing the MNIST dataset. These files come from the [MNIST in CSV](https://www.kaggle.com/datasets/oddrationale/mnist-in-csv) Kaggle dataset.\n",
    "\n",
    "The `mnist_train.csv` file contains 60,000 training examples and labels. The `mnist_test.csv` contains 10,000 test examples and labels. Each row consists of 785 values: the first value is the label (a number from 0 to 9) and the remaining 784 values are the pixel values (a number from 0 to 255)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf401e-0e1f-4ef8-824a-98e975438054",
   "metadata": {},
   "source": [
    "Let's extract the `dataset.tar.gz` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4210d6-f612-4f7b-9b18-397e2a8ac8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/\n",
      "dataset/mnist_test.csv\n",
      "dataset/mnist_train.csv\n"
     ]
    }
   ],
   "source": [
    "MNIST_FOLDER = \"mnist\"\n",
    "DATASET_FOLDER = Path(\"dataset\")\n",
    "\n",
    "!tar -xvzf dataset.tar.gz --no-same-owner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df65826-f4e1-4683-8bfe-b7889bf8eec9",
   "metadata": {},
   "source": [
    "Let's load the first 10 rows of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a47f00d-c97c-4dde-b588-21c1f3782c12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "5      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "6      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "7      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "8      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "9      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "5      0      0      0      0      0      0      0      0  \n",
       "6      0      0      0      0      0      0      0      0  \n",
       "7      0      0      0      0      0      0      0      0  \n",
       "8      0      0      0      0      0      0      0      0  \n",
       "9      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_FOLDER / \"mnist_train.csv\", nrows=1000)\n",
    "df_test = pd.read_csv(DATASET_FOLDER / \"mnist_test.csv\", nrows=1000)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fa35f4a-319b-4f2b-a28b-5ece97af281f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def col_reshape(raw, num_classes, hasLabel=True):\n",
    "    IMG_ROWS = 28\n",
    "    IMG_COLS = 28\n",
    "    start_pixel = 0\n",
    "\n",
    "    if (hasLabel):\n",
    "        start_pixel = 1\n",
    "        \n",
    "    if (hasLabel):\n",
    "        out_y = keras.utils.np_utils.to_categorical(raw.label, num_classes)\n",
    "    else:\n",
    "        out_y = None\n",
    "        \n",
    "    num_images = raw.shape[0]\n",
    "    x_array = raw.values[:, start_pixel:]\n",
    "    x_shaped_array = x_array.reshape(num_images, IMG_ROWS, IMG_COLS, 1)\n",
    "    out_x = x_shaped_array / 255\n",
    "    \n",
    "    return out_x, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a1a9634-b6c5-4fcc-a2b9-48400ebba683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e2728a0-92ba-466b-a79b-23099495ce88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = col_reshape(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b64e63-72f5-40ed-96fe-36e01b3948cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 60k for train, 10k for test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a019d1b-4bac-49c5-98bc-ba64174ab084",
   "metadata": {},
   "source": [
    "## Uploading dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d0d2b41-3239-4004-b20b-25bdd59b6eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set S3 location: s3://ml-school-gibran-2023-mnist/mnist/mnist_train.csv\n",
      "Test set S3 location: s3://ml-school-gibran-2023-mnist/mnist/mnist_test.csv\n"
     ]
    }
   ],
   "source": [
    "S3_FILEPATH = f\"s3://{BUCKET}/{MNIST_FOLDER}\"\n",
    "\n",
    "\n",
    "TRAIN_SET_S3_URI = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=str(DATASET_FOLDER / \"mnist_train.csv\"), \n",
    "    desired_s3_uri=S3_FILEPATH,\n",
    ")\n",
    "\n",
    "TEST_SET_S3_URI = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=str(DATASET_FOLDER / \"mnist_test.csv\"), \n",
    "    desired_s3_uri=S3_FILEPATH,\n",
    ")\n",
    "\n",
    "print(f\"Train set S3 location: {TRAIN_SET_S3_URI}\")\n",
    "print(f\"Test set S3 location: {TEST_SET_S3_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea302b-7a2a-4b42-93a3-52b51919c49e",
   "metadata": {},
   "source": [
    "# Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc125b8-11b5-4eb0-b62e-6ae67f60afba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c895b4-dda5-44be-8d40-7db4771d045b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import argparse\n",
    "import tempfile\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import CacheConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62ce7787-b5a6-4b3e-91dc-f47cf4dbb7e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iam_client = boto3.client(\"iam\")\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "544d0b14-8396-4d2c-b376-27dc2d2b0d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset/preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DATASET_FOLDER}/preprocessor.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from pickle import dump\n",
    "\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "# This is the location where the SageMaker Processing job\n",
    "# will save the input dataset.\n",
    "BASE_DIRECTORY = \"/opt/ml/processing\"\n",
    "DATA_FILEPATH = Path(BASE_DIRECTORY) / \"input\" / \"mnist_train.csv\"\n",
    "\n",
    "\n",
    "def _save_splits(base_directory, train, validation, test):\n",
    "    \"\"\"\n",
    "    One of the goals of this script is to output the three\n",
    "    dataset splits. This function will save each of these\n",
    "    splits to disk.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_path = Path(base_directory) / \"train\" \n",
    "    validation_path = Path(base_directory) / \"validation\" \n",
    "    test_path = Path(base_directory) / \"test\"\n",
    "    \n",
    "    train_path.mkdir(parents=True, exist_ok=True)\n",
    "    validation_path.mkdir(parents=True, exist_ok=True)\n",
    "    test_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    pd.DataFrame(train).to_csv(train_path / \"train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(validation_path / \"validation.csv\", header=False, index=False)\n",
    "    pd.DataFrame(test).to_csv(test_path / \"test.csv\", header=False, index=False)\n",
    "    \n",
    "\n",
    "def _save_pipeline(base_directory, pipeline):\n",
    "    \"\"\"\n",
    "    Saves the Scikit-Learn pipeline that we used to\n",
    "    preprocess the data.\n",
    "    \"\"\"\n",
    "    pipeline_path = Path(base_directory) / \"pipeline\"\n",
    "    pipeline_path.mkdir(parents=True, exist_ok=True)\n",
    "    dump(pipeline, open(pipeline_path / \"pipeline.pkl\", 'wb'))\n",
    "    \n",
    "\n",
    "def _save_classes(base_directory, classes):\n",
    "    \"\"\"\n",
    "    Saves the list of classes from the dataset.\n",
    "    \"\"\"\n",
    "    path = Path(base_directory) / \"classes\"\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"CLASSES\", np.asarray(classes))\n",
    "\n",
    "    np.asarray(classes).tofile(path / \"classes.csv\", sep = \",\") \n",
    "    \n",
    "\n",
    "def _generate_baseline_dataset(split_name, base_directory, X, y):\n",
    "    \"\"\"\n",
    "    To monitor the data and the quality of our model we need to compare the \n",
    "    production quality and results against a baseline. To create those baselines, \n",
    "    we need to use a dataset to compute statistics and constraints. That dataset\n",
    "    should contain information in the same format as expected by the production\n",
    "    endpoint. This function will generate a baseline dataset and save it to \n",
    "    disk so we can later use it.\n",
    "    \n",
    "    \"\"\"\n",
    "    baseline_path = Path(base_directory) / f\"{split_name}-baseline\" \n",
    "    baseline_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = X.copy()\n",
    "    \n",
    "    # The baseline dataset needs a column containing the groundtruth.\n",
    "    df[\"groundtruth\"] = y\n",
    "    df[\"groundtruth\"] = df[\"groundtruth\"].values.astype(str)\n",
    "    \n",
    "    # We will use the baseline dataset to generate baselines\n",
    "    # for monitoring data and model quality. To simplify the process, \n",
    "    # we don't want to include any NaN rows.\n",
    "    df = df.dropna()\n",
    "\n",
    "    df.to_json(baseline_path / f\"{split_name}-baseline.json\", orient='records', lines=True)\n",
    "\n",
    "\n",
    "## reshape columns from 784 to 28, 28, 1\n",
    "def col_reshape(raw, num_classes, hasLabel=True):\n",
    "    IMG_ROWS = 28\n",
    "    IMG_COLS = 28\n",
    "    start_pixel = 0\n",
    "\n",
    "    if (hasLabel):\n",
    "        start_pixel = 1\n",
    "        \n",
    "    if (hasLabel):\n",
    "        out_y = keras.utils.np_utils.to_categorical(raw.label, num_classes)\n",
    "    else:\n",
    "        out_y = None\n",
    "        \n",
    "    num_images = raw.shape[0]\n",
    "    x_array = raw.values[:, start_pixel:]\n",
    "    x_shaped_array = x_array.reshape(num_images, IMG_ROWS, IMG_COLS, 1)\n",
    "    out_x = x_shaped_array / 255\n",
    "    \n",
    "    return out_x, out_y\n",
    "    \n",
    "    \n",
    "def preprocess(base_directory, data_filepath_train, data_filepath_test, target_var):\n",
    "    \"\"\"\n",
    "    Preprocesses the supplied raw dataset and splits it into a train, validation,\n",
    "    and a test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_train = pd.read_csv(data_filepath_train)\n",
    "    df_test = pd.read_csv(data_filepath_test)\n",
    "    \n",
    "    # parameters\n",
    "    NUM_CLASSES = len(df_train.label.unique())\n",
    "    \n",
    "    X, y = col_reshape(df_train, NUM_CLASSES)\n",
    "    X_test, y_test = col_reshape(df_test, NUM_CLASSES)\n",
    "\n",
    "    columns = list((df_train.drop([target_var], axis=1)).columns)\n",
    "    \n",
    "    X, test = X.to_numpy(), X_test.to_numpy()\n",
    "    \n",
    "    np.random.shuffle(X)\n",
    "    train, validation = np.split(X, [int(.8 * len(X))])\n",
    "    \n",
    "    X_train = pd.DataFrame(train, columns=columns)\n",
    "    X_validation = pd.DataFrame(validation, columns=columns)\n",
    "    X_test = pd.DataFrame(test, columns=columns)\n",
    "    \n",
    "    y_train = X_train[target_var]\n",
    "    y_validation = X_validation[target_var]\n",
    "    y_test = X_test[target_var]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    ## IMPORTANT - fit_transform vs transform only\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_validation = label_encoder.transform(y_validation)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "    \n",
    "    X_train.drop([target_var], axis=1, inplace=True)\n",
    "    X_validation.drop([target_var], axis=1, inplace=True)\n",
    "    X_test.drop([target_var], axis=1, inplace=True)\n",
    "\n",
    "    # Let's generate a dataset that we can later use to compute\n",
    "    # baseline statistics and constraints about the data that we\n",
    "    # used to train our model.\n",
    "    _generate_baseline_dataset(\"train\", base_directory, X_train, y_train)\n",
    "    \n",
    "    # To generate baseline constraints about the quality of the\n",
    "    # model's predictions, we will use the test set.\n",
    "    _generate_baseline_dataset(\"test\", base_directory, X_test, y_test)\n",
    "    \n",
    "    # Transform the data using the Scikit-Learn pipeline.\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    X_validation = preprocessor.transform(X_validation)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "    \n",
    "    train = np.concatenate((X_train, np.expand_dims(y_train, axis=1)), axis=1)\n",
    "    validation = np.concatenate((X_validation, np.expand_dims(y_validation, axis=1)), axis=1)\n",
    "    test = np.concatenate((X_test, np.expand_dims(y_test, axis=1)), axis=1)\n",
    "    \n",
    "    _save_splits(base_directory, train, validation, test)\n",
    "    _save_pipeline(base_directory, pipeline=preprocessor)\n",
    "    _save_classes(base_directory, label_encoder.classes_)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess(BASE_DIRECTORY, DATA_FILEPATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a8b44e-71c3-441a-90f4-438329e3607e",
   "metadata": {},
   "source": [
    "## Step 2 - Testing the Preprocessing Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2198992c-f856-4ffa-9257-a8712b8cd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataset.preprocessor import preprocess\n",
    "\n",
    "# with tempfile.TemporaryDirectory() as directory:\n",
    "#     preprocess(\n",
    "#         base_directory=directory, \n",
    "#         data_filepath_train=DATASET_FOLDER/\"mnist_train.csv\",\n",
    "#         data_filepath_test=DATASET_FOLDER/\"mnist_test.csv\",\n",
    "#         target_var='label'\n",
    "#     )\n",
    "    \n",
    "#     print(f\"Folders: {os.listdir(directory)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2c31e1-d0d9-4279-8d41-fd7b6fba8ee5",
   "metadata": {},
   "source": [
    "## Step 3 - Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "583ce50c-94e6-4200-bb55-72a43dd695ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_location = ParameterString(name=\"train_dataset_location\", \n",
    "                                         default_value=TRAIN_SET_S3_URI)\n",
    "\n",
    "test_dataset_location = ParameterString(name=\"test_dataset_location\",\n",
    "                                        default_value=TEST_SET_S3_URI)\n",
    "\n",
    "preprocessor_destination = ParameterString(\n",
    "    name=\"preprocessor_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing\",\n",
    ")\n",
    "\n",
    "train_dataset_baseline_destination = ParameterString(\n",
    "    name=\"train_dataset_baseline_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing/baselines/train\",\n",
    ")\n",
    "\n",
    "test_dataset_baseline_destination = ParameterString(\n",
    "    name=\"test_dataset_baseline_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing/baselines/test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e04eaa1-530b-4cde-93f9-2d10a17e0b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_config = CacheConfig(\n",
    "    enable_caching=True, \n",
    "    expire_after=\"15d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5158eb10-71a2-4e8f-9d37-143c5b792bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    base_job_name=\"mnist-preprocessing\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "preprocess_data_step = ProcessingStep(\n",
    "    name=\"preprocess-data\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=train_dataset_location, destination=\"/opt/ml/processing/train\"),\n",
    "        ProcessingInput(source=test_dataset_location, destination=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"pipeline\", source=\"/opt/ml/processing/pipeline\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"classes\", source=\"/opt/ml/processing/classes\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"train-baseline\", source=\"/opt/ml/processing/train-baseline\", destination=train_dataset_baseline_destination),\n",
    "        ProcessingOutput(output_name=\"test-baseline\", source=\"/opt/ml/processing/test-baseline\", destination=test_dataset_baseline_destination),\n",
    "    ],\n",
    "    code=f\"{DATASET_FOLDER}/preprocessor.py\",\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e398f3ed-1caf-43ff-931a-28383929aac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session1_pipeline = Pipeline(\n",
    "    name=\"mnist-session1-pipeline\",\n",
    "    parameters=[\n",
    "        train_dataset_location, \n",
    "        test_dataset_location, \n",
    "        preprocessor_destination,\n",
    "        train_dataset_baseline_destination,\n",
    "        test_dataset_baseline_destination\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_data_step, \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1088143b-73c5-418e-97b0-1b331712dc93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session1_pipeline.upsert(role_arn=role)\n",
    "execution = session1_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d536eb3-c92f-412e-8a29-6447abeea570",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 2 - Model Training and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7cb53a3d-0daf-4df7-838e-f0f28ab1b552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## source: https://www.kaggle.com/code/gpreda/simple-introduction-to-cnn-for-mnist-99-37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7b314bb-2817-449c-97a5-0ae21deb2a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "311b804e-0777-4e96-9d40-df4662cb0a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_FOLDER / \"mnist_train.csv\", nrows=6000)\n",
    "columns = list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "21f99127-dc8a-4e2f-a1c7-993e693adad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.to_numpy()\n",
    "np.random.shuffle(df)\n",
    "train, validation = np.split(df, [int(.8 * len(X))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d9b0f01b-da2f-483a-9d3f-24e4dee05c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(train, columns=columns)\n",
    "X_val = pd.DataFrame(validation, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eef1074b-c9b2-49da-aa7c-8fc2ee7e3312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, BatchNormalization\n",
    "\n",
    "X_train, y_train = col_reshape(X_train, 10)\n",
    "X_val, y_val = col_reshape(X_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "10718423-789f-479b-a74e-ce4dacf8b551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMG_ROWS = 28\n",
    "IMG_COLS = 28\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "def modeling():\n",
    "    # Model\n",
    "    model = Sequential()\n",
    "    # Add convolution 2D\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu', padding=\"same\",\n",
    "            kernel_initializer='he_normal',input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(32,kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # Add dropouts to the model\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), strides=2,padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), strides=2,padding='same', activation='relu'))\n",
    "    # Add dropouts to the model\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # Add dropouts to the model\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f47eb396-6fc1-4377-bfec-8957849dafd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = modeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "26c8f757-2904-4eea-8ecd-ca2c96b2d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dff41a1f-da84-4980-9c83-d32da82dabd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 13, 13, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 6, 6, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 100,874\n",
      "Trainable params: 100,554\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b3f4de27-8d46-4af5-8a18-47bc60dfb684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "NO_EPOCHS = 100\n",
    "PATIENCE = 20\n",
    "VERBOSE = 1\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9aeeaf85-3362-4e7a-9ce0-71e3bd6a8c60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 4s 411ms/step - loss: 2.2656 - accuracy: 0.1650 - val_loss: 2.2933 - val_accuracy: 0.1587\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "7/7 [==============================] - 2s 339ms/step - loss: 2.1585 - accuracy: 0.2387 - val_loss: 2.2706 - val_accuracy: 0.2179\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "7/7 [==============================] - 2s 326ms/step - loss: 2.0405 - accuracy: 0.2887 - val_loss: 2.2274 - val_accuracy: 0.3142\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "7/7 [==============================] - 2s 332ms/step - loss: 1.9072 - accuracy: 0.3725 - val_loss: 2.1391 - val_accuracy: 0.4094\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "7/7 [==============================] - 2s 337ms/step - loss: 1.8067 - accuracy: 0.3837 - val_loss: 2.0617 - val_accuracy: 0.3513\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "7/7 [==============================] - 2s 328ms/step - loss: 1.6702 - accuracy: 0.4387 - val_loss: 2.0049 - val_accuracy: 0.3148\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "7/7 [==============================] - 2s 326ms/step - loss: 1.5411 - accuracy: 0.4888 - val_loss: 1.9069 - val_accuracy: 0.3612\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "7/7 [==============================] - 2s 324ms/step - loss: 1.3735 - accuracy: 0.5475 - val_loss: 1.8716 - val_accuracy: 0.3333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "7/7 [==============================] - 2s 331ms/step - loss: 1.2173 - accuracy: 0.6037 - val_loss: 1.9114 - val_accuracy: 0.2787\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "7/7 [==============================] - 2s 334ms/step - loss: 1.0651 - accuracy: 0.6538 - val_loss: 2.0773 - val_accuracy: 0.1619\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "7/7 [==============================] - 2s 335ms/step - loss: 0.9459 - accuracy: 0.7075 - val_loss: 2.0090 - val_accuracy: 0.2171\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "7/7 [==============================] - 2s 327ms/step - loss: 0.8359 - accuracy: 0.7337 - val_loss: 2.4465 - val_accuracy: 0.1446\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "7/7 [==============================] - 2s 322ms/step - loss: 0.7151 - accuracy: 0.7750 - val_loss: 2.3910 - val_accuracy: 0.1627\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "7/7 [==============================] - 2s 329ms/step - loss: 0.6116 - accuracy: 0.8238 - val_loss: 2.3001 - val_accuracy: 0.2258\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "7/7 [==============================] - 2s 337ms/step - loss: 0.5163 - accuracy: 0.8375 - val_loss: 2.5640 - val_accuracy: 0.1852\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "7/7 [==============================] - 2s 332ms/step - loss: 0.4657 - accuracy: 0.8537 - val_loss: 2.7860 - val_accuracy: 0.1435\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "7/7 [==============================] - 2s 322ms/step - loss: 0.4099 - accuracy: 0.8675 - val_loss: 3.2971 - val_accuracy: 0.1212\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "7/7 [==============================] - 2s 329ms/step - loss: 0.3294 - accuracy: 0.8975 - val_loss: 3.5980 - val_accuracy: 0.1225\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "7/7 [==============================] - 2s 328ms/step - loss: 0.3055 - accuracy: 0.9062 - val_loss: 3.6099 - val_accuracy: 0.1288\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "7/7 [==============================] - 2s 330ms/step - loss: 0.2889 - accuracy: 0.9125 - val_loss: 3.8732 - val_accuracy: 0.1206\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "7/7 [==============================] - 2s 335ms/step - loss: 0.2745 - accuracy: 0.9200 - val_loss: 4.1526 - val_accuracy: 0.1162\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "7/7 [==============================] - 2s 381ms/step - loss: 0.2553 - accuracy: 0.9237 - val_loss: 5.2385 - val_accuracy: 0.1112\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "7/7 [==============================] - 2s 336ms/step - loss: 0.2034 - accuracy: 0.9425 - val_loss: 3.9540 - val_accuracy: 0.1723\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "7/7 [==============================] - 3s 497ms/step - loss: 0.1692 - accuracy: 0.9575 - val_loss: 3.4560 - val_accuracy: 0.2148\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "7/7 [==============================] - 2s 338ms/step - loss: 0.1772 - accuracy: 0.9475 - val_loss: 3.6566 - val_accuracy: 0.1908\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "7/7 [==============================] - 2s 324ms/step - loss: 0.1871 - accuracy: 0.9500 - val_loss: 3.4842 - val_accuracy: 0.2171\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "7/7 [==============================] - 2s 330ms/step - loss: 0.1422 - accuracy: 0.9563 - val_loss: 3.6875 - val_accuracy: 0.1900\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "7/7 [==============================] - 2s 327ms/step - loss: 0.1261 - accuracy: 0.9588 - val_loss: 3.4658 - val_accuracy: 0.2052\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "7/7 [==============================] - 2s 340ms/step - loss: 0.1397 - accuracy: 0.9563 - val_loss: 2.8843 - val_accuracy: 0.2892\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "7/7 [==============================] - 2s 325ms/step - loss: 0.1171 - accuracy: 0.9663 - val_loss: 2.9758 - val_accuracy: 0.2983\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "7/7 [==============================] - 2s 325ms/step - loss: 0.1230 - accuracy: 0.9650 - val_loss: 3.0346 - val_accuracy: 0.3208\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "7/7 [==============================] - 2s 331ms/step - loss: 0.0921 - accuracy: 0.9712 - val_loss: 2.5245 - val_accuracy: 0.4073\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "7/7 [==============================] - 2s 327ms/step - loss: 0.1195 - accuracy: 0.9638 - val_loss: 1.9776 - val_accuracy: 0.5015\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "7/7 [==============================] - 2s 335ms/step - loss: 0.0847 - accuracy: 0.9787 - val_loss: 2.2428 - val_accuracy: 0.4369\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "7/7 [==============================] - 2s 327ms/step - loss: 0.0820 - accuracy: 0.9800 - val_loss: 2.0975 - val_accuracy: 0.4663\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "7/7 [==============================] - 2s 327ms/step - loss: 0.1037 - accuracy: 0.9725 - val_loss: 1.9919 - val_accuracy: 0.5015\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "7/7 [==============================] - 2s 328ms/step - loss: 0.0896 - accuracy: 0.9762 - val_loss: 1.9318 - val_accuracy: 0.5298\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "7/7 [==============================] - 2s 330ms/step - loss: 0.0936 - accuracy: 0.9750 - val_loss: 1.1297 - val_accuracy: 0.6992\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "7/7 [==============================] - 2s 339ms/step - loss: 0.0934 - accuracy: 0.9650 - val_loss: 1.0527 - val_accuracy: 0.7273\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "7/7 [==============================] - 2s 325ms/step - loss: 0.0632 - accuracy: 0.9837 - val_loss: 1.0087 - val_accuracy: 0.7469\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "7/7 [==============================] - 2s 329ms/step - loss: 0.0843 - accuracy: 0.9762 - val_loss: 1.2977 - val_accuracy: 0.6775\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "7/7 [==============================] - 2s 342ms/step - loss: 0.0810 - accuracy: 0.9825 - val_loss: 1.5677 - val_accuracy: 0.6127\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "7/7 [==============================] - 2s 334ms/step - loss: 0.0694 - accuracy: 0.9775 - val_loss: 0.7275 - val_accuracy: 0.8110\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "7/7 [==============================] - 2s 326ms/step - loss: 0.0629 - accuracy: 0.9812 - val_loss: 0.5797 - val_accuracy: 0.8488\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "7/7 [==============================] - 2s 324ms/step - loss: 0.0687 - accuracy: 0.9800 - val_loss: 0.6133 - val_accuracy: 0.8363\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "7/7 [==============================] - 2s 328ms/step - loss: 0.0682 - accuracy: 0.9837 - val_loss: 0.8154 - val_accuracy: 0.8131\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "7/7 [==============================] - 2s 325ms/step - loss: 0.0541 - accuracy: 0.9837 - val_loss: 0.7751 - val_accuracy: 0.8187\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "7/7 [==============================] - 2s 338ms/step - loss: 0.0766 - accuracy: 0.9737 - val_loss: 0.5652 - val_accuracy: 0.8558\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "7/7 [==============================] - 2s 331ms/step - loss: 0.0511 - accuracy: 0.9887 - val_loss: 0.4561 - val_accuracy: 0.8837\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "7/7 [==============================] - 2s 325ms/step - loss: 0.0485 - accuracy: 0.9837 - val_loss: 0.4547 - val_accuracy: 0.8848\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "7/7 [==============================] - 2s 332ms/step - loss: 0.0619 - accuracy: 0.9812 - val_loss: 0.5331 - val_accuracy: 0.8658\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "7/7 [==============================] - 3s 536ms/step - loss: 0.0552 - accuracy: 0.9800 - val_loss: 0.5785 - val_accuracy: 0.8569\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "7/7 [==============================] - 2s 344ms/step - loss: 0.0524 - accuracy: 0.9837 - val_loss: 0.5046 - val_accuracy: 0.8725\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "7/7 [==============================] - 2s 323ms/step - loss: 0.0438 - accuracy: 0.9862 - val_loss: 0.3901 - val_accuracy: 0.9021\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "7/7 [==============================] - 2s 332ms/step - loss: 0.0565 - accuracy: 0.9812 - val_loss: 0.3408 - val_accuracy: 0.9140\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "7/7 [==============================] - 2s 327ms/step - loss: 0.0539 - accuracy: 0.9812 - val_loss: 0.3416 - val_accuracy: 0.9127\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "7/7 [==============================] - 2s 339ms/step - loss: 0.0729 - accuracy: 0.9812 - val_loss: 0.2879 - val_accuracy: 0.9227\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "7/7 [==============================] - 2s 328ms/step - loss: 0.0656 - accuracy: 0.9750 - val_loss: 0.2712 - val_accuracy: 0.9331\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "7/7 [==============================] - 2s 324ms/step - loss: 0.0594 - accuracy: 0.9775 - val_loss: 0.2661 - val_accuracy: 0.9388\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "7/7 [==============================] - 2s 328ms/step - loss: 0.0645 - accuracy: 0.9825 - val_loss: 0.2969 - val_accuracy: 0.9333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "7/7 [==============================] - 2s 325ms/step - loss: 0.0691 - accuracy: 0.9750 - val_loss: 0.3044 - val_accuracy: 0.9342\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "7/7 [==============================] - 2s 339ms/step - loss: 0.0466 - accuracy: 0.9862 - val_loss: 0.3019 - val_accuracy: 0.9342\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "7/7 [==============================] - 2s 325ms/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 0.3110 - val_accuracy: 0.9288\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "7/7 [==============================] - 2s 331ms/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 0.3074 - val_accuracy: 0.9300\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "7/7 [==============================] - 2s 326ms/step - loss: 0.0519 - accuracy: 0.9862 - val_loss: 0.2947 - val_accuracy: 0.9331\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "7/7 [==============================] - 2s 324ms/step - loss: 0.0478 - accuracy: 0.9887 - val_loss: 0.3118 - val_accuracy: 0.9323\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "7/7 [==============================] - 2s 345ms/step - loss: 0.0379 - accuracy: 0.9887 - val_loss: 0.3022 - val_accuracy: 0.9344\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "7/7 [==============================] - 2s 324ms/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 0.2822 - val_accuracy: 0.9375\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "7/7 [==============================] - 2s 330ms/step - loss: 0.0281 - accuracy: 0.9950 - val_loss: 0.2686 - val_accuracy: 0.9437\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "7/7 [==============================] - 2s 324ms/step - loss: 0.0403 - accuracy: 0.9862 - val_loss: 0.2877 - val_accuracy: 0.9358\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "7/7 [==============================] - 2s 331ms/step - loss: 0.0270 - accuracy: 0.9925 - val_loss: 0.2890 - val_accuracy: 0.9365\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "7/7 [==============================] - 2s 361ms/step - loss: 0.0353 - accuracy: 0.9912 - val_loss: 0.3039 - val_accuracy: 0.9308\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "7/7 [==============================] - 2s 326ms/step - loss: 0.0362 - accuracy: 0.9912 - val_loss: 0.2994 - val_accuracy: 0.9350\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "7/7 [==============================] - 2s 332ms/step - loss: 0.0379 - accuracy: 0.9912 - val_loss: 0.2874 - val_accuracy: 0.9377\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "7/7 [==============================] - 2s 325ms/step - loss: 0.0401 - accuracy: 0.9900 - val_loss: 0.2800 - val_accuracy: 0.9413\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "7/7 [==============================] - 2s 331ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.2639 - val_accuracy: 0.9446\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "7/7 [==============================] - 2s 337ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.2801 - val_accuracy: 0.9419\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "7/7 [==============================] - 2s 329ms/step - loss: 0.0233 - accuracy: 0.9950 - val_loss: 0.3064 - val_accuracy: 0.9388\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "7/7 [==============================] - 2s 329ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.2857 - val_accuracy: 0.9435\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "7/7 [==============================] - 3s 442ms/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 0.2572 - val_accuracy: 0.9473\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "7/7 [==============================] - 3s 401ms/step - loss: 0.0307 - accuracy: 0.9937 - val_loss: 0.2476 - val_accuracy: 0.9477\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "7/7 [==============================] - 2s 324ms/step - loss: 0.0256 - accuracy: 0.9925 - val_loss: 0.2515 - val_accuracy: 0.9456\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "7/7 [==============================] - 2s 332ms/step - loss: 0.0515 - accuracy: 0.9812 - val_loss: 0.2459 - val_accuracy: 0.9471\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "7/7 [==============================] - 2s 326ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.2489 - val_accuracy: 0.9506\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "7/7 [==============================] - 2s 333ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 0.2565 - val_accuracy: 0.9490\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "7/7 [==============================] - 2s 335ms/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 0.2574 - val_accuracy: 0.9508\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "7/7 [==============================] - 2s 330ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 0.2576 - val_accuracy: 0.9515\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "7/7 [==============================] - 2s 324ms/step - loss: 0.0272 - accuracy: 0.9937 - val_loss: 0.2564 - val_accuracy: 0.9517\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "7/7 [==============================] - 2s 323ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.2465 - val_accuracy: 0.9546\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "7/7 [==============================] - 2s 331ms/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 0.2461 - val_accuracy: 0.9531\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "7/7 [==============================] - 2s 336ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.2562 - val_accuracy: 0.9498\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "7/7 [==============================] - 2s 331ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.2839 - val_accuracy: 0.9431\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "7/7 [==============================] - 2s 327ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.2870 - val_accuracy: 0.9402\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "7/7 [==============================] - 2s 325ms/step - loss: 0.0250 - accuracy: 0.9900 - val_loss: 0.2869 - val_accuracy: 0.9415\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "7/7 [==============================] - 2s 350ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.3191 - val_accuracy: 0.9329\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "7/7 [==============================] - 2s 334ms/step - loss: 0.0311 - accuracy: 0.9925 - val_loss: 0.3220 - val_accuracy: 0.9342\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "7/7 [==============================] - 2s 331ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.2989 - val_accuracy: 0.9365\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00097: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "earlystopper = EarlyStopping(monitor='loss', patience=PATIENCE, verbose=VERBOSE)\n",
    "checkpointer = ModelCheckpoint('best_model.h5',\n",
    "                                monitor='val_acc',\n",
    "                                verbose=VERBOSE,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NO_EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val),\n",
    "          callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b1d11a51-f446-4e08-9c1e-048a7336e5a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.2656495571136475,\n",
       "  2.1584877967834473,\n",
       "  2.040471315383911,\n",
       "  1.9071776866912842,\n",
       "  1.8066881895065308,\n",
       "  1.6701576709747314,\n",
       "  1.5410516262054443,\n",
       "  1.3734877109527588,\n",
       "  1.2172600030899048,\n",
       "  1.0650876760482788,\n",
       "  0.9458809494972229,\n",
       "  0.8358756303787231,\n",
       "  0.7150549292564392,\n",
       "  0.611640214920044,\n",
       "  0.5162917971611023,\n",
       "  0.4657489061355591,\n",
       "  0.4099295139312744,\n",
       "  0.3294370770454407,\n",
       "  0.3054705560207367,\n",
       "  0.28892067074775696,\n",
       "  0.2745261788368225,\n",
       "  0.25525030493736267,\n",
       "  0.203445166349411,\n",
       "  0.1691737174987793,\n",
       "  0.17724500596523285,\n",
       "  0.18709148466587067,\n",
       "  0.1421828418970108,\n",
       "  0.12608444690704346,\n",
       "  0.13968366384506226,\n",
       "  0.1170697957277298,\n",
       "  0.12300405651330948,\n",
       "  0.09212538599967957,\n",
       "  0.11954484134912491,\n",
       "  0.0846906304359436,\n",
       "  0.08201109617948532,\n",
       "  0.10367272049188614,\n",
       "  0.08963456749916077,\n",
       "  0.09356426447629929,\n",
       "  0.0934014767408371,\n",
       "  0.06322778016328812,\n",
       "  0.08429780602455139,\n",
       "  0.08101370185613632,\n",
       "  0.06941109895706177,\n",
       "  0.06286761909723282,\n",
       "  0.06868045032024384,\n",
       "  0.06820935010910034,\n",
       "  0.0540616512298584,\n",
       "  0.07662222534418106,\n",
       "  0.05106116458773613,\n",
       "  0.04845941439270973,\n",
       "  0.061925191432237625,\n",
       "  0.05515249818563461,\n",
       "  0.05240309610962868,\n",
       "  0.043838921934366226,\n",
       "  0.05648517236113548,\n",
       "  0.0538652241230011,\n",
       "  0.0728786289691925,\n",
       "  0.06555716693401337,\n",
       "  0.059362638741731644,\n",
       "  0.06448297202587128,\n",
       "  0.06906719505786896,\n",
       "  0.046570487320423126,\n",
       "  0.038040030747652054,\n",
       "  0.04838621988892555,\n",
       "  0.051919709891080856,\n",
       "  0.04779202491044998,\n",
       "  0.037869568914175034,\n",
       "  0.03752654790878296,\n",
       "  0.028057537972927094,\n",
       "  0.040340982377529144,\n",
       "  0.026959240436553955,\n",
       "  0.03529074788093567,\n",
       "  0.03620342165231705,\n",
       "  0.03794686496257782,\n",
       "  0.040112901479005814,\n",
       "  0.03332308679819107,\n",
       "  0.01561586931347847,\n",
       "  0.02333516627550125,\n",
       "  0.03620045259594917,\n",
       "  0.034229472279548645,\n",
       "  0.030667012557387352,\n",
       "  0.02555808238685131,\n",
       "  0.051530756056308746,\n",
       "  0.0277010016143322,\n",
       "  0.02501649223268032,\n",
       "  0.01646057888865471,\n",
       "  0.032909587025642395,\n",
       "  0.027160927653312683,\n",
       "  0.021384434774518013,\n",
       "  0.03130827471613884,\n",
       "  0.019941924139857292,\n",
       "  0.018003283068537712,\n",
       "  0.021362032741308212,\n",
       "  0.025000765919685364,\n",
       "  0.027802007272839546,\n",
       "  0.031086336821317673,\n",
       "  0.026336610317230225],\n",
       " 'accuracy': [0.16500000655651093,\n",
       "  0.23874999582767487,\n",
       "  0.2887499928474426,\n",
       "  0.3725000023841858,\n",
       "  0.38374999165534973,\n",
       "  0.4387499988079071,\n",
       "  0.48875001072883606,\n",
       "  0.5475000143051147,\n",
       "  0.6037499904632568,\n",
       "  0.6537500023841858,\n",
       "  0.7074999809265137,\n",
       "  0.7337499856948853,\n",
       "  0.7749999761581421,\n",
       "  0.8237500190734863,\n",
       "  0.8374999761581421,\n",
       "  0.8537499904632568,\n",
       "  0.8675000071525574,\n",
       "  0.8974999785423279,\n",
       "  0.90625,\n",
       "  0.9125000238418579,\n",
       "  0.9200000166893005,\n",
       "  0.9237499833106995,\n",
       "  0.9424999952316284,\n",
       "  0.9574999809265137,\n",
       "  0.9474999904632568,\n",
       "  0.949999988079071,\n",
       "  0.956250011920929,\n",
       "  0.9587500095367432,\n",
       "  0.956250011920929,\n",
       "  0.9662500023841858,\n",
       "  0.9649999737739563,\n",
       "  0.9712499976158142,\n",
       "  0.9637500047683716,\n",
       "  0.9787499904632568,\n",
       "  0.9800000190734863,\n",
       "  0.9725000262260437,\n",
       "  0.9762499928474426,\n",
       "  0.9750000238418579,\n",
       "  0.9649999737739563,\n",
       "  0.9837499856948853,\n",
       "  0.9762499928474426,\n",
       "  0.9825000166893005,\n",
       "  0.9775000214576721,\n",
       "  0.981249988079071,\n",
       "  0.9800000190734863,\n",
       "  0.9837499856948853,\n",
       "  0.9837499856948853,\n",
       "  0.9737499952316284,\n",
       "  0.9887499809265137,\n",
       "  0.9837499856948853,\n",
       "  0.981249988079071,\n",
       "  0.9800000190734863,\n",
       "  0.9837499856948853,\n",
       "  0.9862499833106995,\n",
       "  0.981249988079071,\n",
       "  0.981249988079071,\n",
       "  0.981249988079071,\n",
       "  0.9750000238418579,\n",
       "  0.9775000214576721,\n",
       "  0.9825000166893005,\n",
       "  0.9750000238418579,\n",
       "  0.9862499833106995,\n",
       "  0.9887499809265137,\n",
       "  0.9850000143051147,\n",
       "  0.9862499833106995,\n",
       "  0.9887499809265137,\n",
       "  0.9887499809265137,\n",
       "  0.9887499809265137,\n",
       "  0.9950000047683716,\n",
       "  0.9862499833106995,\n",
       "  0.9925000071525574,\n",
       "  0.9912499785423279,\n",
       "  0.9912499785423279,\n",
       "  0.9912499785423279,\n",
       "  0.9900000095367432,\n",
       "  0.9900000095367432,\n",
       "  0.9962499737739563,\n",
       "  0.9950000047683716,\n",
       "  0.987500011920929,\n",
       "  0.9912499785423279,\n",
       "  0.9937499761581421,\n",
       "  0.9925000071525574,\n",
       "  0.981249988079071,\n",
       "  0.9912499785423279,\n",
       "  0.9912499785423279,\n",
       "  0.9962499737739563,\n",
       "  0.9912499785423279,\n",
       "  0.9937499761581421,\n",
       "  0.9937499761581421,\n",
       "  0.9912499785423279,\n",
       "  0.9937499761581421,\n",
       "  0.9950000047683716,\n",
       "  0.9925000071525574,\n",
       "  0.9900000095367432,\n",
       "  0.9912499785423279,\n",
       "  0.9925000071525574,\n",
       "  0.9925000071525574],\n",
       " 'val_loss': [2.29329776763916,\n",
       "  2.2706222534179688,\n",
       "  2.227386474609375,\n",
       "  2.1390979290008545,\n",
       "  2.061702251434326,\n",
       "  2.0049026012420654,\n",
       "  1.9069061279296875,\n",
       "  1.871561050415039,\n",
       "  1.9114439487457275,\n",
       "  2.0772690773010254,\n",
       "  2.0090131759643555,\n",
       "  2.4465079307556152,\n",
       "  2.3910181522369385,\n",
       "  2.300055980682373,\n",
       "  2.564013957977295,\n",
       "  2.7859694957733154,\n",
       "  3.2971224784851074,\n",
       "  3.5980329513549805,\n",
       "  3.6099274158477783,\n",
       "  3.8731629848480225,\n",
       "  4.152633190155029,\n",
       "  5.238519668579102,\n",
       "  3.953951358795166,\n",
       "  3.4560084342956543,\n",
       "  3.6565680503845215,\n",
       "  3.484177350997925,\n",
       "  3.687490701675415,\n",
       "  3.465791702270508,\n",
       "  2.884296417236328,\n",
       "  2.9757583141326904,\n",
       "  3.03462815284729,\n",
       "  2.5244500637054443,\n",
       "  1.9775874614715576,\n",
       "  2.2427706718444824,\n",
       "  2.0974602699279785,\n",
       "  1.991882085800171,\n",
       "  1.9317669868469238,\n",
       "  1.1297025680541992,\n",
       "  1.0526795387268066,\n",
       "  1.0087357759475708,\n",
       "  1.2977477312088013,\n",
       "  1.5676604509353638,\n",
       "  0.7274826765060425,\n",
       "  0.5796943306922913,\n",
       "  0.6132602095603943,\n",
       "  0.8153718709945679,\n",
       "  0.7751125693321228,\n",
       "  0.5652011632919312,\n",
       "  0.45610594749450684,\n",
       "  0.45470482110977173,\n",
       "  0.533054769039154,\n",
       "  0.5785201191902161,\n",
       "  0.5046183466911316,\n",
       "  0.3901063799858093,\n",
       "  0.3408278524875641,\n",
       "  0.3415672183036804,\n",
       "  0.2878949046134949,\n",
       "  0.27123507857322693,\n",
       "  0.2661193311214447,\n",
       "  0.29694435000419617,\n",
       "  0.3043661117553711,\n",
       "  0.3018728494644165,\n",
       "  0.31096601486206055,\n",
       "  0.3074187636375427,\n",
       "  0.2946521043777466,\n",
       "  0.31184425950050354,\n",
       "  0.30221179127693176,\n",
       "  0.28222376108169556,\n",
       "  0.2686416208744049,\n",
       "  0.2876569628715515,\n",
       "  0.28899455070495605,\n",
       "  0.30385828018188477,\n",
       "  0.29943859577178955,\n",
       "  0.2873821258544922,\n",
       "  0.27996766567230225,\n",
       "  0.2639169692993164,\n",
       "  0.2801034450531006,\n",
       "  0.30643489956855774,\n",
       "  0.28572407364845276,\n",
       "  0.257161021232605,\n",
       "  0.2475898563861847,\n",
       "  0.25151827931404114,\n",
       "  0.24587202072143555,\n",
       "  0.24893029034137726,\n",
       "  0.25654029846191406,\n",
       "  0.25743240118026733,\n",
       "  0.25756168365478516,\n",
       "  0.25644904375076294,\n",
       "  0.24650219082832336,\n",
       "  0.24611638486385345,\n",
       "  0.2561843991279602,\n",
       "  0.2838728725910187,\n",
       "  0.2869904339313507,\n",
       "  0.2869272530078888,\n",
       "  0.3190952241420746,\n",
       "  0.3220210671424866,\n",
       "  0.2989059090614319],\n",
       " 'val_accuracy': [0.1586538404226303,\n",
       "  0.2178846150636673,\n",
       "  0.3142307698726654,\n",
       "  0.4094230830669403,\n",
       "  0.3513461649417877,\n",
       "  0.3148076832294464,\n",
       "  0.36115384101867676,\n",
       "  0.33326923847198486,\n",
       "  0.2786538600921631,\n",
       "  0.16192308068275452,\n",
       "  0.2171153873205185,\n",
       "  0.14461538195610046,\n",
       "  0.16269230842590332,\n",
       "  0.22576923668384552,\n",
       "  0.1851923018693924,\n",
       "  0.14346154034137726,\n",
       "  0.12115384638309479,\n",
       "  0.12250000238418579,\n",
       "  0.1288461536169052,\n",
       "  0.12057692557573318,\n",
       "  0.11615384370088577,\n",
       "  0.11115384846925735,\n",
       "  0.17230768501758575,\n",
       "  0.2148076891899109,\n",
       "  0.190769225358963,\n",
       "  0.2171153873205185,\n",
       "  0.1899999976158142,\n",
       "  0.20519231259822845,\n",
       "  0.2892307639122009,\n",
       "  0.29826924204826355,\n",
       "  0.32076922059059143,\n",
       "  0.4073076844215393,\n",
       "  0.5015384554862976,\n",
       "  0.436923086643219,\n",
       "  0.4663461446762085,\n",
       "  0.5015384554862976,\n",
       "  0.5298076868057251,\n",
       "  0.6992307901382446,\n",
       "  0.7273076772689819,\n",
       "  0.7469230890274048,\n",
       "  0.6775000095367432,\n",
       "  0.6126922965049744,\n",
       "  0.8109615445137024,\n",
       "  0.8488461375236511,\n",
       "  0.8363461494445801,\n",
       "  0.813076913356781,\n",
       "  0.8186538219451904,\n",
       "  0.8557692170143127,\n",
       "  0.8836538195610046,\n",
       "  0.8848077058792114,\n",
       "  0.8657692074775696,\n",
       "  0.8569231033325195,\n",
       "  0.8725000023841858,\n",
       "  0.9021154046058655,\n",
       "  0.9140384793281555,\n",
       "  0.9126923084259033,\n",
       "  0.9226922988891602,\n",
       "  0.9330769181251526,\n",
       "  0.9388461709022522,\n",
       "  0.933269202709198,\n",
       "  0.9342307448387146,\n",
       "  0.9342307448387146,\n",
       "  0.9288461804389954,\n",
       "  0.9300000071525574,\n",
       "  0.9330769181251526,\n",
       "  0.9323077201843262,\n",
       "  0.9344230890274048,\n",
       "  0.9375,\n",
       "  0.9436538219451904,\n",
       "  0.935769259929657,\n",
       "  0.9365384578704834,\n",
       "  0.9307692050933838,\n",
       "  0.9350000023841858,\n",
       "  0.9376922845840454,\n",
       "  0.9413461685180664,\n",
       "  0.944615364074707,\n",
       "  0.9419230818748474,\n",
       "  0.9388461709022522,\n",
       "  0.943461537361145,\n",
       "  0.9473077058792114,\n",
       "  0.947692334651947,\n",
       "  0.9455769062042236,\n",
       "  0.9471153616905212,\n",
       "  0.950576901435852,\n",
       "  0.9490384459495544,\n",
       "  0.9507692456245422,\n",
       "  0.9515384435653687,\n",
       "  0.9517307877540588,\n",
       "  0.9546154141426086,\n",
       "  0.9530768990516663,\n",
       "  0.9498077034950256,\n",
       "  0.9430769085884094,\n",
       "  0.9401922821998596,\n",
       "  0.9415384531021118,\n",
       "  0.9328846335411072,\n",
       "  0.9342307448387146,\n",
       "  0.9365384578704834]}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "352e9855-4a44-48fe-803a-7c87d9e3c94d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzkAAAF1CAYAAADLFyQnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAACVKklEQVR4nOzdeVzU1f7H8ddhB1EQEBVRcdfcUHHJ3bRcMst2s9Rs38263fZsvdX13qxfZdliWZpli3UzMy3XXFFx11xCBXeUTXY4vz8OwyYg4sx8Yfg8Hw8eAzPf+c6HsZh5zznnc5TWGiGEEEIIIYRwFW5WFyCEEEIIIYQQ9iQhRwghhBBCCOFSJOQIIYQQQgghXIqEHCGEEEIIIYRLkZAjhBBCCCGEcCkScoQQQgghhBAuRUKOQCm1UCk13t7HWkkpFauUGuKA82qlVMv87z9QSj1XkWMr8ThjlVK/VbZOIYQQhrzGXdB5q/VrnFJqoFIqzt7nFdWTh9UFiMpRSqUW+dEPyARy83++R2s9u6Ln0loPd8Sxrk5rfa89zqOUigD+Bjy11jn5554NVPjfUAghXIm8xllPXuNEdSchp5rSWvvbvldKxQJ3aq2XlDxOKeVh+6MihNXkv0chREXIa5wQ4mLJdDUXYxuqVUr9Uyl1DJiplKqrlPpZKXVSKXUm//vwIvdZppS6M//7CUqpVUqpqfnH/q2UGl7JY5sppVYopVKUUkuUUu8ppb4so+6K1PiyUurP/PP9ppQKKXL7bUqpg0qpBKXUM+U8Pz2VUseUUu5FrhutlNqa/30PpdQapVSiUuqoUupdpZRXGef6TCn1SpGf/5F/nyNKqYkljr1SKbVZKZWslDqslJpS5OYV+ZeJSqlUpdSltue2yP17K6U2KKWS8i97V/S5ucDnOUgpNTP/dzijlJpf5LarlVIx+b/DfqXUsPzri02bUEpNsf07K6Ui8qc03KGUOgT8kX/9vPx/h6T8/0baF7m/r1LqP/n/nkn5/435KqUWKKUeKvH7bFVKjS7tdxVCuB4lr3HyGlfOa1wpv0O7/PsnKqV2KKVGFblthFJqZ/4545VSj+dfH5L/75OolDqtlFqplJL3y9WQ/KO5pgZAENAUuBvz7zwz/+cmQDrwbjn37wnsAUKAN4FPlFKqEsfOAdYDwcAU4LZyHrMiNd4C3A6EAl6A7Q/SJcD0/POH5T9eOKXQWq8DzgKXlTjvnPzvc4FH83+fS4HBwP3l1E1+DcPy67kcaAWUnCt9FhgHBAJXAvcppa7Jv61//mWg1tpfa72mxLmDgAXAO/m/23+BBUqp4BK/wznPTSnO9zx/gZka0j7/XG/l19ADmAX8I/936A/ElvEYpRkAtAOG5v+8EPM8hQKbKD5tYSrQDeiN+e/4CSAP+By41XaQUqoz0Ajz3Aghag55jZPXuLJe44qe1xP4H/Bb/v0eAmYrpdrkH/IJZupjbaAD+R/CAY8BcUA9oD7wNKDP93ii6pGQ45rygBe01pla63StdYLW+jutdZrWOgV4FfOmsywHtdYfaa1zMW8sG2L+R6/wsUqpJkB34HmtdZbWehXwU1kPWMEaZ2qt/9JapwPfAJH5118P/Ky1XqG1zgSey38OyvIVMAZAKVUbGJF/HVrrjVrrtVrrHK11LPBhKXWU5sb8+rZrrc9iXvCK/n7LtNbbtNZ5Wuut+Y9XkfOCecHYq7X+Ir+ur4DdwFVFjinruSmmvOdZKdUQGA7cq7U+o7XO1lovz7/rHcCnWuvF+b9DvNZ6dwXrB5iitT6bXx9a60+11in5/15TgM5KqYD8T8smAo/kP0au1np1/nE/Aa2VUq3yz3kb8LXWOusC6hBCVH/yGievcZEVOG8vwB94Pf/f6A/gZ/KfGyAbuEQpVSf/NW9TkesbAk3zXwdXaq0l5FRDEnJc00mtdYbtB6WUn1Lqw/yh7mTM0HFg0eHsEo7ZvtFap+V/63+Bx4YBp4tcB3C4rIIrWOOxIt+nFakprOi58/8AJ5T1WJhPtK5VSnkD1wKbtNYH8+tonT9MfSy/jtcwn3idT7EagIMlfr+eSqml+VMVkoB7K3he27kPlrjuIGYUw6as56aY8zzPjTH/ZmdKuWtjYH8F6y1NwXOjlHJXSr2uzJS3ZApHhELyv3xKe6z8/6a/Bm7ND0NjMCNPQoiaRV7j5DWurH+vc2rWWhcNhEXPex0mAB5USi1XSl2af/2/gX3Ab0qpA0qpJyv2a4iqRkKOayr5icNjQBugp9a6DoVDx2UNz9vDUSBIKeVX5LrG5Rx/MTUeLXru/McMLutgrfVOzB+64RQfxgczJWA30Cq/jqcrUwNmOkJRczCf8jXWWgcAHxQ57/k+ITqCmeJQVBMgvgJ1lVTe83wY828WWMr9DgMtyjjnWcwUN5sGpRxT9He8BbgaM90hAIgoUsMpIKOcx/ocGIuZYpGmS0x7EELUCPIaJ69xFXEEaFxiPU3BebXWG7TWV2Omss3HjBCRP8vgMa11c2AUMFkpNfgiaxEWkJBTM9TGzP9NzJ/7+oKjHzD/U6NoYIpSyiv/E5KryrnLxdT4LTBSKdVXmQWUL3H+/7bnAI9gXmjmlagjGUhVSrUF7qtgDd8AE5RSl+S/AJWsvzbmU7+M/PUttxS57SRm6kHzMs79C2aa1i1KKQ+l1E3AJZhh9wtV5vOstT6KWSvzvjKLZD2VUrYX4k+A25VSg5VSbkqpRvnPD0AMcHP+8VGYqRXnqyET80mkH+aTRFsNecCnwH+VUmH5oz6X5n8iSX6oyQP+g4ziCCEMeY07V019jStqHWbU54n816eBmH+jufn/ZmOVUgFa62zMc5IHoJQaqZRqqZRSQBJmHVN50wNFFSUhp2aYBvhiPiVfC/zqpMcdi1nYmAC8gplqlFnGsdOoZI1a6x3AA5g/6keBM5hFg+WxzRf+Q2t9qsj1j2P+OKcAH+XXXJEaFub/Dn9ghrn/KHHI/cBLSqkU4HnyPzHKv28aZn72n8p0c+lV4twJwEjMJ4EJmIX4I0vUXVHTKP95vg0zH3k3cAKYlF/Desyiz7cwf/SXU/jJ23OYkZczwIsU/9SwNLMwnzLGAzvz6yjqcWAbsAE4DbxB8b9Vs4COQKldjIQQNc405DWupJr6Glf0vFmYUDMc87y/D4wrsp70NiA2f9revZh/TzCNFZYAqcAa4H2t9dKLqUVYQ8laKuEsSqmvgd1aa4d/yiZcl1JqHHC31rqv1bUIIYSNvMYJUbXISI5wGKVUd6VUi/zpTcMw6zDmW1yWqMbyp0ncD8ywuhYhRM0mr3FCVG0eVhcgXFoD4HvMAsk44D6t9WZrSxLVlVJqKOa/pyWcf0qcEEI4mrzGCVGFyXQ1IYQQQgghhEuR6WpCCCGEEEIIlyIhRwghhBBCCOFSLFuTExISoiMiIqx6eCGEEMDGjRtPaa3rWV1HVSSvU0IIYb3Kvk5ZFnIiIiKIjo626uGFEEIASqmDVtdQVcnrlBBCWK+yr1MyXU0IIYQQQgjhUiTkCCGEEEIIIVyKhBwhhBBCCCGES5HNQIUQQgghhEvKzs4mLi6OjIwMq0sR5+Hj40N4eDienp52OZ+EHCGEEEII4ZLi4uKoXbs2ERERKKWsLkeUQWtNQkICcXFxNGvWzC7nlOlqQgghhBDCJWVkZBAcHCwBp4pTShEcHGzXETcJOUIIIYQQwmVJwKke7P3vJCFHCCGEEEIIB0hISCAyMpLIyEgaNGhAo0aNCn7Oysoq977R0dE8/PDD532M3r1726XWZcuWMXLkSLucqyo475ocpdSnwEjghNa6Qym3K+BtYASQBkzQWm+yd6FCCCGEEEJUJ8HBwcTExAAwZcoU/P39efzxxwtuz8nJwcOj9LfjUVFRREVFnfcxVq9ebZdaXU1FRnI+A4aVc/twoFX+193A9IsvSwghhBBCCNczYcIE7r33Xnr27MkTTzzB+vXrufTSS+nSpQu9e/dmz549QPGRlSlTpjBx4kQGDhxI8+bNeeeddwrO5+/vX3D8wIEDuf7662nbti1jx45Faw3AL7/8Qtu2benWrRsPP/zweUdsTp8+zTXXXEOnTp3o1asXW7duBWD58uUFI1FdunQhJSWFo0eP0r9/fyIjI+nQoQMrV660+3NWGecdydFar1BKRZRzyNXALG2exbVKqUClVEOt9VF7FSmEEEIIIcTFmPTrJGKOxdj1nJENIpk2bNoF3y8uLo7Vq1fj7u5OcnIyK1euxMPDgyVLlvD000/z3XffnXOf3bt3s3TpUlJSUmjTpg333XffOe2WN2/ezI4dOwgLC6NPnz78+eefREVFcc8997BixQqaNWvGmDFjzlvfCy+8QJcuXZg/fz5//PEH48aNIyYmhqlTp/Lee+/Rp08fUlNT8fHxYcaMGQwdOpRnnnmG3Nxc0tLSLvj5cAR7tJBuBBwu8nNc/nXnhByl1N2Y0R6aNGlih4cWQtQ0209sJzMnk6aBTQn2dV7HnPjkeHLycmga2NQpjyeEyzp2DLy8ICjI6kqEsMwNN9yAu7s7AElJSYwfP569e/eilCI7O7vU+1x55ZV4e3vj7e1NaGgox48fJzw8vNgxPXr0KLguMjKS2NhY/P39ad68eUFr5jFjxjBjxoxy61u1alVB0LrssstISEggOTmZPn36MHnyZMaOHcu1115LeHg43bt3Z+LEiWRnZ3PNNdcQGRl5MU+N3Th1nxyt9QxgBkBUVJR25mMLIRxj+4ntPP7b43Su35nXBr+Gu5t7sdu11nYJIifPnuTxxY8za8usgutqedaiX9N+zBg5g8YBjUu9X1JGEqsOreJg0kGaBDQhIjCCiMAI/L38K/S4B84c4NUVrzJr6yxy83IZ03EMz/V/jrYhbdFasydhD6sOrSI5M7ngPsG+wfRv2p+IQLMvg9aaA2cOsPzgcvac2kNsUiyxibFk52bTt0lfBkYMpH/T/oT4hZy3npy8HHLzcgt+Vkrh5e5Vod9FiCrh+uuhWTP44gurKxE1TGVGXBylVq1aBd8/99xzDBo0iB9++IHY2FgGDhxY6n28vb0Lvnd3dycnJ6dSx1yMJ598kiuvvJJffvmFPn36sGjRIvr378+KFStYsGABEyZMYPLkyYwbN86uj1sZ9gg58UDRdxfh+dcJIVxYWnYaLy9/malrpuLt7s2i/Yv46/RfzL52Nn6efmTlZvHvP//Nv1b9C28P74JwEegdWGroUSjq+9cvOC7INwiFOS76SDRP/v4kKZkpPN33aXo06kFsYiz7z+xnZsxMIj+MZNY1s7iy9ZUA7D61my+2fMFvB35j09FN5Om8Yo/l4ebB9Cunc2fXO4tdv+34Nt7f8D7ZeeZTtDMZZ/hx9494uHlwX9R9+Hj48N6G9/hq21cMiBjArpO7OH72eJnPUeM6jencoDMxx2KIS44DwMvdi6YBTYkIjCBP5/HJ5k/4v/X/B0CH0A4MbDqQAREDCPAOIDbRhCFbKIpNjOVoylE0hZ8R9QrvxZo71lzoP58Q1omPBx8fq6sQospISkqiUaNGAHz22Wd2P3+bNm04cOAAsbGxRERE8PXXX5/3Pv369WP27Nk899xzLFu2jJCQEOrUqcP+/fvp2LEjHTt2ZMOGDezevRtfX1/Cw8O56667yMzMZNOmTS4Tcn4CHlRKzQV6AkmyHke4ujPpZ7jn53vo37Q/d3a9Ex+Pqv+CnZ6dztq4tSw/uJz18euJbBDJ+M7jaRPSpthxWblZRB+JZlnsMlYeWklSRlKp5zuYdJAjKUe4PfJ23rz8TeZsm8OkXydx2eeX8VTfp3jq96fYdWoXV7e5mob+DTmYdJCdJ3eSkplS6vnydB4nzp4gV+eWenvfJn35cOSHXFLvkmLXP9jjQW6cdyMjvxrJhMgJ7Dq5i3Xx63BX7vRu3Jtn+z3LgIgBtA5uTVxyHAcTD/Lx5o+55+d7qF+rPle1uQqAzUc3M3jWYLJyswj0CQTA3c2dB7o/wD/7/pOw2mEA/KP3P/jPmv/w818/c3mLyxnQdAD9m/angX+DgpoOJR1ieexylh1cxrbj2+jduHdBeGkb0hY3VdjzxfZ8L/17KcsPLufTmE95d8O7Bbe7K3caBzQmIjCCK1pcQZM6TYr992arS4hqIyUFUlOtrkKIKuOJJ55g/PjxvPLKK1x55ZV2P7+vry/vv/8+w4YNo1atWnTv3v2897E1OujUqRN+fn58/vnnAEybNo2lS5fi5uZG+/btGT58OHPnzuXf//43np6e+Pv7M2vWrPOc3TmUretCmQco9RUwEAgBjgMvAJ4AWusP8ltIv4vpwJYG3K61jj7fA0dFReno6PMeJsR5Zedm4+nuef4DK+h0+mkyczILfm7g3+CckYdxP4zji61mqkVY7TCe7PMkd3a9E19P3/PWuuHIBpbFLmNZ7DL2nd7HhMgJPNzz4YI31o7w6eZPuX/B/WTmZuKm3Ggd3Jq9CXvJ1bn0Cu9FlwZdOJR0iNjEWA6cOUB6TjpgRhYa+jcs9Zy+nr482utRBkYMLLhu/u753PLdLaTnpNM0oCnvX/k+I1qNqHCdOXk5xCfH83fi38XCVR3vOgyIGFAsHBSVkZPB5EWTmR49nQ6hHZjQeQJjO40tFjyKOpt1lkGfD2L7ie38Mf4PvNy9GDJrCLW9a7Ns/DKa1W1W4ZrtLTs3m01HN5GRk0Gzus0Iqx2Gh5vjZhYrpTZqrc/fo7QGktcpB9AavL2hdWvYvt3qakQNsGvXLtq1a2d1GZZLTU3F398frTUPPPAArVq14tFHH7W6rHOU9u9V2dep84YcR5EXD2EPtjfvbwx5g4d7PlwQRrJzs/kg+gNOnD3B/d3vp2HtwjfqWmt2ntxJrs6laUBTAnwCSMpI4psd3/D5ls/58/CfxR5jQNMB/HzLzwVrOH7a8xNXz72a5/s/z8CIgUxZPoUVB1fg4+FDr/BeDGw6kD5N+tAyqCXhdcJxV+7EHIvhs5jPmLN9DqfSTgHQMbQj9f3rs+TAEgK8A3i016P0a9qv1N/Tdu6y3uQDrI1by6ebP2Vil4n0Cu9VcP3/9vyPa76+hgFNBzD50sn0bdKXQJ9AjqYcZfa22czaMovDyYcLpok1D2xO3yZ96de0X4XWiJS06egmlv69lHuj7qWWV63z38GOUrNSqeVZq0JrgE6cPUGfT/twJv0MeTqPOt51WDp+qaUBxwoScsomr1MOkJEBvr7QtCnExlpdjagBJOQYb731Fp9//jlZWVl06dKFjz76CD8/P6vLOoeEHFFtxSfH88XWLwrWF5zJOMOTfZ5kdLvRF3yu1KxUWr7TkpSsFNKy07im7TV8OupT9iTs4Z6f72Hr8a0oFN4e3tzd9W7u6HoHi/cv5rMtn7H9ROEniIE+gWTkZJCRk0HbkLbc0uEWQmuFAuaN8IvLX+TSxpfyyy2/kJWbRYfpHahfqz7r71pfsOB7xcEV/Lj7R5YdXMbmo5sL1ky4K3eCfIM4mXYSL3cvRrUZxc3tb2ZAxICCALH56GZeWvES83fPL/f37RXeiw9Hfkin+p2KXb/m8BpeXP4ii/YvAsx6k9cue43Hej/G+vj1XPb5ZbQPbc/S8UsrvNi+pth/ej+9P+2Nr4cvyyYsIyIwwuqSnE5CTtnkdcoBTpyA+vUhJAROnrS6GlEDSMipXuwZcpzaXU3UbFm5WYyYM4Ktx7cS4hdCRGAEqVmpXPvNtTzU4yH+ffm/8fbwJi07jfm757Pp6CbC64TTNKApLYNa0iG0Q7FP6Ketncbxs8dZPXE1a+LW8M8l/6TNu204lXaKsNphfH/j93Sq34lXV77Kexve4531ZuOsXuG9eH/E+4T4hXAw6SCxibF4uHlwS8db6B7W/ZxRgLYhbRnz3RiGzx5Ow9oNOZV2ioVjFxbraNW/aX/6N+0PmPU6m45uKghycSlxdA/rzs0dbibI99yWqV0aduGHm35gb8JejqaWvpxtz6k9PP3H03T9sCuTL51M14ZdC6a87UnYQ4hfCG8MeYOxHcfyyK+P8MSSJ/j979+JPhJNWO0wFtyyQAJOKVoEtWDH/TvwdPMkwCfA6nKEcH3J+V0IZU2OEMLBZCRHOM3zS5/n5RUv8+PNPzKqzSgAMnMy+eeSf/L2urfp1rAbXRp04Zud35CcmYynm2dBlyuAu7rexQcjP8BNuXHy7ElavNOCwc0H88NNPwCwLm4d9y24j/5N+/PyoJep7V274L4Hzhxg4d6FDG4+mLYhbS+49nk75jHmuzHk6lxeGPACUwZOubgnoxJOp5/mn4v/ycebPwbMOpV+TfoxtMVQbu9ye0GI0Vrz/ob3mfzbZAK8A1hzxxpaBLVwer2iepCRnLLJ65QDbNoE3bqZ77OzwUM+axWOJSM51YuM5IgqKzs3m7fXvc3MmJm8POhlrm13LWDWaby28jXGdR5XEHAAvD28mTZsGgMjBnL7j7ez+9Rurr/kesZ3Hs+AiAGcST9DbGIsX23/iv+s+Q9aaz686kNeW/kaZ7PP8tplrxWcq2d4Tzbds6nUuprXbc4DPR6o9O91Q/sb8Pbw5pe9v/B0v6crfZ6LEeQbxEejPuLhng+TmZtJZIPIUhekK6V4oMcDXNHiCtOuWDavFEJUFcmF+0lx9iwEyAiqEMIxJOSISjuUdIiMnAyaBJiWtmvj1hashalfqz7XfXMdD/V4iFcve5UJ8ydQ378+04ZOK/Vc17S9hqEthpKn84otVg/2CybYL5iuDbvi5+nHyyteJikziR/3/MiEzhNoV895n86MajOqWECzSsf6HSt0XKvgVg6uRAghLlDRkJOaKiFHCOEwZbdqEqIc3+z4huZvN6fNu23wfdWXhv9pSO9PepOQlsD3N37PoUcPMannJP5v/f/R7O1mbDuxjRkjZ1DXt26Z5/T19C2zG5dSihcHvsjz/Z9n3s55KJQlU8aEEEJchJIhRwgXN2jQIBYtWlTsumnTpnHfffeVeZ+BAwdimyo7YsQIEhMTzzlmypQpTJ06tdzHnj9/Pjt37iz4+fnnn2fJkiUXUH3pli1bxsiRIy/6PI4mIznign29/WvGfj+W3o17c2fXOwsW2IfVDuOfff5ZsBbmrWFvFUxDu7vr3QW70VeWUooXB71Iw9oN8ffyp3FAY3v8OkKIGkQpFQukALlAjqxHcrKS09WEcHFjxoxh7ty5DB06tOC6uXPn8uabb1bo/r/88kulH3v+/PmMHDmSSy4xm2i/9NJLlT5XdSQhp4bQWrPl+BY6hHao0MaCsYmxLItdxoqDK9BoBjQdwMCIgayLW8fY78fSp0mfCnXsurrt1RxrdQxPN/tt1nlv1L12O5cQokYapLU+ZXURNZKM5Iga5vrrr+fZZ58lKysLLy8vYmNjOXLkCP369eO+++5jw4YNpKenc/311/Piiy+ec/+IiAiio6MJCQnh1Vdf5fPPPyc0NJTGjRvTLb+Jx0cffcSMGTPIysqiZcuWfPHFF8TExPDTTz+xfPlyXnnlFb777jtefvllRo4cyfXXX8/vv//O448/Tk5ODt27d2f69Ol4e3sTERHB+PHj+d///kd2djbz5s2jbduyGzadPn2aiRMncuDAAfz8/JgxYwadOnVi+fLlPPLII4D5kHrFihWkpqZy0003kZycTE5ODtOnT6dfv9L3B7QHCTk1xMyYmdzx0x3c2P5GZl87u8yg8+PuH/nH4n+w9/ReAIJ9gwH4LOazgmP6N+1/QS2Ji7ZaFsKlaQ0xMXDsmNnRPSIC3N2trkqIqkNCjrDSpEnmb7Q9RUbCtGll3hwUFESPHj1YuHAhV199NXPnzuXGG29EKcWrr75KUFAQubm5DB48mK1bt9KpU6dSz7Nx40bmzp1LTEwMOTk5dO3atSDkXHvttdx1110APPvss3zyySc89NBDjBo1qiDUFJWRkcGECRP4/fffad26NePGjWP69OlMmjQJgJCQEDZt2sT777/P1KlT+fjjj8v8/V544QW6dOnC/Pnz+eOPPxg3bhwxMTFMnTqV9957jz59+pCamoqPjw8zZsxg6NChPPPMM+Tm5pKWllbx57kSJOTUAIeTDvPookdpXKcx3+z4Bq01s6+djae7Z7FjHlr4ED/u+ZEOoR14Z9g7DIwYSPvQ9gDsPLmTZbHLSEhL4LHej8meK6Lmyc2FU6cgIcFcnjljWuBmZ0N6Ovz5JyxcCEeL7HXk5QVt2sCIEXDddRAVBSX2YRJOp4HflFIa+FBrPaPojUqpu4G7AZo0aWJBeS5OQo6ogWxT1mwh55NPPgHgm2++YcaMGeTk5HD06FF27txZZshZuXIlo0ePxs/PD4BRowobIW3fvp1nn32WxMREUlNTi02NK82ePXto1qwZrVu3BmD8+PG89957BSHn2mtNZ9xu3brx/fffl3uuVatW8d133wFw2WWXkZCQQHJyMn369GHy5MmMHTuWa6+9lvDwcLp3787EiRPJzs7mmmuuITIysvwn7iJJyHFxWmvu+t9d5OblsmzCMn7Y9QOPL34cjeZfg//FqkOrWH5wOfN2zCNP5/HmkDeZ1GtSsQAE0CG0Ax1CO1j0WwhxkbQ2X25l9Fo5dQq++w6++srs49G8uQknLVrAkSOwfTvs3GnCTFkCA+GKK0ygad4c9u6FPXvM+f7zH3jjDWja1HyS+NBDMsJjnb5a63ilVCiwWCm1W2u9wnZjfuiZAWafHKuKdFnJyea//dxcCTnC+coZcXGkq6++mkcffZRNmzaRlpZGt27d+Pvvv5k6dSobNmygbt26TJgwgYyMjEqdf8KECcyfP5/OnTvz2WefsWzZsouq19vbGwB3d3dycnIqdY4nn3ySK6+8kl9++YU+ffqwaNEi+vfvz4oVK1iwYAETJkxg8uTJjBs37qJqLY+EHBf3yeZPWLR/Ee+NeI/mdZvzWO/HAHh88eN8u/NbwExJu7rt1bx62atEBEZYWK0QdnD6NMyZA7NmQWwspKWZLx8f6NoVevSATp3gxAkTQnbvhnXrzJuutm1h7Fg4dAg2boRvv4X69aFjR7jvPhNeQkIgOBjq1jUjNV5e4OkJTZoU39iw6Dzj06fhf/8zNT36qDnvzJnQStp8O5vWOj7/8oRS6gegB7Ci/HsJu0lOhoYNIS5OGg+IGsPf359BgwYxceJExowZA0BycjK1atUiICCA48ePs3DhQgYOHFjmOfr378+ECRN46qmnyMnJ4X//+x/33HMPACkpKTRs2JDs7Gxmz55No0aNAKhduzYpKSnnnKtNmzbExsayb9++gjU8AwYMqNTv1q9fP2bPns1zzz3HsmXLCAkJoU6dOuzfv5+OHTvSsWNHNmzYwO7du/H19SU8PJy77rqLzMxMNm3aJCFHVM6hpENMXjSZQRGDii3Wf6z3Y7QMasnh5MMMjBjIJfUuwU1JN3FRSUlJ8OabcMklJiDYy7FjMH++GWGJjjbhZMgQuPxyE1JKjsqsWQNvvw0//ABZWSbQXHcd1KoFfn6QkgIbNsD06WD7tKx+fTNi849/wJgxJswUnU6Wm2ufEZegIBg/HsaNg9mzzUhO587w7LNw880mPAmHU0rVAty01in5318B1Kx2Q1YrGnJkJEfUIGPGjGH06NHMnTsXgM6dO9OlSxfatm1L48aN6dOnT7n379q1KzfddBOdO3cmNDSU7t27F9z28ssv07NnT+rVq0fPnj0Lgs3NN9/MXXfdxTvvvMO3335bcLyPjw8zZ87khhtuKGg8cO+9lWvqNGXKFCZOnEinTp3w8/Pj888/B0yb7KVLl+Lm5kb79u0ZPnw4c+fO5d///jeenp74+/sza9asSj1mRSmtrRmNj4qK0rYe4MIxrvvmOhbtW8S2+7bRrG4zq8sRrkZr+PprMzJx7Ji57p57TNDIH+q+YMnJJtR88QUsW2Yeo3Vr6N0b1q83U8YAwsJg1CjzlZ0N//43rFplpoyNGwe3324Wg5YmOxsOHDABJzCwcnVerCNH4O67YcEC83Pr1nDZZeZN3/798Pff0L8/fPIJ+Dt2/ZtSamNNaaOslGoO/JD/owcwR2v9alnHy+uUA0RFmf/3Fi2Cf/4TXi3z6RfCLnbt2kW7ds7bOFxcnNL+vSr7OiUjOS5qbdxavt/1PS8OfFECjqvautUEjK1b4bHH4JFHwNfX8Y+bnGzeoHz4Ifz+O3TrZkZcfvjBrDuJiTEhxdPTLNJPTYVLLzXTukoTFweLF8Ovv8JPP5lRlpYt4bnn4IYboH37wtGV+Hhz7M8/m8f44ANzfZMmZq71HXecPxR4eprRGyuFhZnfYe9e06xg4UL48kszDa55cxgwAObNM7f//LM5vqTcXLNWKDm5+NQ4USat9QGgs9V11GjJySbU+/vLSI4QwqEk5LggrTVPLnmS0FqhTL50stXlCHs7edIEgI8+MiMRXbrAU0+ZaVgvvmimghw7Zrp8FW3PWLcuTJwIAQFln1trc9/atc00L6XMG5GNG81Iyu+/w9KlZjpYSAi8+y7ce6+Z0tWzp5lSNn68eRNTVMuWZvH9VVeZcx4/buqfPdusiQHz6e7EiXDbbeZcpXUha9QIJkwwXxkZppaMDBg50oSX6qZVK/P18MPn3jZ+PNx4o3kuvvrKTM87cMAEn7VrzVdysvn337TJ+bULURnJyVCnjoQcIYTDSchxQb/u+5XlB5fzf8P/T1o9u5q9e82n/CdOwIMPwgsvmPUeS5fC44+baVpFFQ0KWsMrr8DTT8MDD5iF+GCC0Jo18OOPZiTl4EFzvbe3CUYnTkBenrmudWuznuTqq83ojEeJPyHXXmvWtfz8swlgwcEmhEyZYu4zZIgJM998Y6aNXXYZ3HWXWWfTocOFtVf28YHhwy/k2atehg+HlStNgCs6UqOUea5uuQX69DFfQlQXRUOONB4QQjiQhBwXk6fzeOr3p2hetzl3d7vb6nKEPcXGwuDBJhxERxdfczJokFlUv2KFCR4NG0KDBmY0xmbzZjPi8/jj8NZbEBpquoglJJjbfXxM2Jg0yYzUnDpluoKFh5sRmu7doV6989fZqpWZRlfU6NFmpGnKFDPN6v77zVfJER9RXGSk+XddsMBMWWvRwrShtgVUIaoT255SdeqYv00ykiOcRGuNkj3Kqjx79wmQkONivtr2FVuOb2H2tbPxci9jDYSofuLizKhHSooZtSltUb2bG5TTfpIuXcy6l6VLzUJ9pUx4adzYjL4MGWK6kDmCp6eZknV3fvCWN+kV17Ah3Hmn1VUIcfFsrWxluppwIh8fHxISEggODpagU4VprUlISMDHju8PJOS4iK3Ht/JZzGfMjJlJZINIbu5ws9UlCXs5dsyM4Jw6ZdbEXOwOwYMGmS8rSLgRouZKTjaXtpBz/Li19YgaITw8nLi4OE6ePGl1KeI8fHx8CA8Pt9v5JORUc6sPr+ahhQ+x6egmPN08uarNVbwy6BXZ98ZVHD1qAkl8vOloVqQvvhBCVCslQ87+/dbWI2oET09PmjWTLrM1kYScaipP5zF19VSe/v1pGgc05p1h7zCm4xhC/EKsLk3Yy5EjJuAcOWKmmckCcyFEdVYy5Mh0NSGEA0nIqYZOpZ1i3A/jWLhvIddfcj0fX/UxAT7ltAUWVV92NvzjH2bkpkULiIgwLZcl4AghXEXJkCPd1YQQDiQhpxrRWvPF1i947LfHSM5M5r0R73Ff1H2ykK6609p0Gvv4Y2jWDL7/HnJyzJsACThCCFdRNOTYuqtpfWGt44UQooIk5FQTfyX8xX0L7uOPv//g0vBL+XDkh3Ss39HqsoQ9vPWWCThPPw2vvmoCTny8CTnBwVZXJ4QQ9lFyJCcnx7Sr9/a2ti4hhEuSkFMN/Lj7R8Z8NwZvD28+uPID7up2lzQWcBX/+5/Zt+a66+Dll811Hh5mLxQhhHAlJVtIgxnNkZAjhHAACTlV3Dvr3mHSr5Po3qg782+aT8PaDa0uSdjLvn1m1/quXWHWLLPPjRBCuKrkZDM1rVat4iFHRqyFEA4gIaeKys3L5fHfHmfaumlc0/YaZl87Gz9PB23UKKzx8ceQkQHz5ztuE04hhKgqkpOhdm0TdGwhR5oPCCEcRD46rqI+3/I509ZN4+EeD/PtDd9KwHE1WsPXX8OQIWDHja+EEKLKSk42U9XAjOaAtJEWQjiMhJwqas62ObQKasW0YdNwd3O3uhxhb9HREBsLN95odSVCCOEcRUNO0elqQgjhABJyqqCTZ0+yNHYpN7a/UdpDu6qvvwZPT7jmGqsrEUII55CQI4RwIgk5VdD3u74nT+dxY3v5lN8l5eXBN9/A0KFQt67V1QghhHNIyBFCOJGEnCpo3s55tA5uTcdQ2QenysrJgRdegOuvhx49oGFDuPvuit137Vo4fBhuusmxNQohRFVSWsiRxgNCCAeRkFPFnDh7wkxVu0SmqlVpixbBSy9BTIwZjWndGj76CDZsOP99v/nG7AsxapTDyxRCiCpDGg8IIZxIWkhXMTJVrZr48kuzt8POneDlZV68mzeHp5+GxYvLvl9eHsybB8OHF77YCyFETSAhRwjhRDKSU8XM2zmPNsFt6BDawepSRFmSk83eNjfdZAIOmBfup5+GJUvgjz/Kvu+qVXDkiExVE0LULHl5kJJSGHI8Pc2ItoQcIYSDSMipQk6cPcGy2GXSVa2q++EHs4nnrbcWv/7++82eN08/bfbBKc0XX4CvL4wc6fg6hRCiqjh71vxdLDqC7e8vIUcI4TAScqoQmapWTXz5pZma1qtX8et9fEwzgnXr4Kefzr3f+vXw6adw++2Fi26FEKImSE42lyVDjjQeEEI4iIScKiIjJ4P3NrxHu5B2tK/X3upyRFni4+H3380oTmmjbRMmmCYEzzwD6emF12dlwR13QIMG8NprTitXCCGqhLJCjozkCCEcREJOFfGP3/7B9hPbmXrFVJmqVpV99ZWZclFyqpqNhwdMnWoaEgweDKdOmevfeAO2b4fp0yEgwHn1CiFEVVBayKlVS0KOEMJhJORUAT/u/pF3N7zLo70eZUSrEVaXI8rz5ZfQsye0alX2MVddZTqobdoEvXvDggXwyitw443SNloIUTPJSI4Qwskk5FgsLjmOiT9NpGvDrvxr8L+sLkeUZ9s22LKl7FGcoq67zkxrS0gwTQZq1YJ33nF8jUIIURVJyBFCOJmEHAvl5uUy9vuxZOZkMve6uXh7eFtdkijPN9+Au3vF2z/36QOrV0PfvvDxx1C/vmPrE0KIqkpCjhDCyWQzUAt9uPFDVhxcwcyrZ9IquJzpT6Jq+O03M1WtXr2K36dNG1i50nE1CSFEdSDd1YQQTiYjORY5lnqMp35/iiHNhzC+83iry6lZtDZTyP7734rf58wZiI6Gyy93XF1CCOGqbCGndu3C66TxgBDCgWQkxyKTF00mMyeT90e8L93UnG3fPtMMYMECaNmyYs0A/vjD7NgtIUcIIS5ccjL4+ZkOlDa2kZy8PHCTz1yFEPYlf1UssHj/Yr7a/hVP9X1KpqlZYckSc9mypWkisHv3+e/z22/mE8gePRxbmxBCuKLk5OJT1cCEHK2L7ykmhBB2IiHHyTJyMrj/l/tpFdSKf/b9p9Xl1ExLlkCTJqb7mY8PXHMNJCWVf5/Fi2HQIPD0dEqJQgjhUsoKOSBT1oQQDiEhx8meX/o8+07v4/0r38fHw8fqcmqe3Fwz9WzIEBN0vv0W9u+H228v+z7798Pff8MVVzivTiGEcCXlhRxpPiCEcAAJOU702/7f+Pfqf3N317sZ0nyI1eXUTJs3Q2KiCTkA/fvDlCnwww8QE1P6fX77zVzKehwhhKic0kJOrVrmUkZyhBAOICHHSY6nHmfcD+NoX689bw17y+pyai7bepzLLiu87oEHzILYsjbrXLzYjPq0kvVTQghRKTJdTQjhZBJynCBP5zF+/niSMpOYe/1c/Dz9rC6p5lqyBDp2LL4xZ2AgjB8Pc+bAyZPFj8/JMdPbLr8cpAueEEJUjoQcIYSTSchxgmlrp7Fo/yLeGvoWHUI7WF1OzZWeDqtWFU5VK+qhhyAzE2bMKH59dLRpSiBT1YQQovIk5AghnExCjhP8d81/ubz55dzT7R6rS6nZ/vzTBJnSQk67dqaxwPvvQ3Z24fW//WZGcAYPdl6dQgjhSrSGlJTiG4GCNB4QQjiUhBwHO5pylPiUeEa0GiGbflptyRKzEV3//qXf/vDDcOQIfPed+fmvv+Crr6BrVwgJcV6dQgjhSjIzzYdHMpIjhHAij/MfIi5G9JFoAKLCoiyuRPD779CrV+ELa0nDh5sNQv/zH1i9GqZPN/vofPaZU8sUQgiXkpxsLqW7mhDCiWQkx8E2HNmAm3KjS4MuVpdSs50+DRs3lj5VzcbNzazNiY6G996DO+6AffvguuucV6cQQriaskKOX34THgk5QggHkJEcB9twZAPt67Wnllctq0up2dauNfPCBw4s/7i77jIvuNdcA5dc4ozKhBDCtR04YC7Dwopf7+ZmRnMk5AghHKBCIzlKqWFKqT1KqX1KqSdLub2JUmqpUmqzUmqrUmqE/UutfrTWRB+JpntYd6tLEadPm8uGDcs/ztcXnn5aAo4QQtjL+vWmgUu3bufe5u8vIUcI4RDnDTlKKXfgPWA4cAkwRilV8h3gs8A3WusuwM3A+/YutDo6mHSQU2mnZD1OVZCSYi5LdvcRQgjhWOvWQdu2EBBw7m3+/tJdTQjhEBUZyekB7NNaH9BaZwFzgatLHKMB22TbAOCI/UqsvjbEbwCgeyMZybGchBwhhHA+rc1ITs+epd8u09WEEA5SkZDTCDhc5Oe4/OuKmgLcqpSKA34BHirtREqpu5VS0Uqp6JMld5Z3QdFHovFy96JT/U5WlyJSUsx0iVqyNkoIIZzm0CE4cQJ69Cj9dpmuJoRwEHt1VxsDfKa1DgdGAF8opc45t9Z6htY6SmsdVa9ePTs9dNW14cgGOtfvjJe7l9WliJQU82IqexUJUaMppdzz14/+bHUtNcK6deZSQo4QwskqEnLigcZFfg7Pv66oO4BvALTWawAfoEbvnpin89h4dKOsx6kqStttWwhREz0C7LK6iBpj/Xrw9oaOHUu/XUKOEMJBKhJyNgCtlFLNlFJemMYCP5U45hAwGEAp1Q4Tclx/Plo59ibsJTkzWTqrVRUScoSo8ZRS4cCVwMdW11JjrF8PXbuCVxkzGqTxgBDCQc4bcrTWOcCDwCLMp1/faK13KKVeUkqNyj/sMeAupdQW4CtggtZaO6ro6mDDEWk6UKVIyBFCwDTgCSDP4jpqhpwcswlzWVPVQEZyhBAOU6HNQLXWv2AaChS97vki3+8E+ti3tOptQ/wG/Dz9aBfSzupSBEjIEaKGU0qNBE5orTcqpQaWc9zdwN0ATZo0cU5xrmrHDkhLKz/kSHc1IYSD2KvxgChhw5ENdG3YFXc3d6tLESAhRwjRBxillIrFbIVwmVLqy5IH1bQGOQ61fr25LKt9NJiRnIwMM+ojhBB2JCHHAXLycth8bLOsx6lKJOQIUaNprZ/SWodrrSMwa0v/0FrfanFZrm39eggKgubNyz7GtkFoYqJTShJC1BwSchxg2/FtZORkSMipSlJTJeQIIYQzrVtnpqqV17o/PNxcxsU5pyYhRI0hIccBVh5aCUDfJn0trkQUkJEcIUQ+rfUyrfVIq+twaampZk1OeetxAJo2NZcHDzq+JiFEjSIhxwFWHFxBRGAEjQMan/9g4Xg5OWbOt4QcIYRwjk2bIC+v/PU4ALbmDocOOb4mIUSNIiHHzrTWrDi4ggFNB1hdirBJSTGX/v7W1iGEEDXFunXmsvt5pm3Xqwc+PjKSI4SwOwk5drb71G5Opp2kf9P+VpcibGwhR0ZyhBDCOdauNQ0HztehTikzmiMjOUIIO5OQY2crDq4AkJBTlUjIEUII59EaVq+G3r0rdryEHCGEA0jIsbMVh1bQ0L8hLeq2sLoUYSMhRwghnOfgQTh2DC69tGLHN20q09WEEHYnIceOtNYsj13OgIgBqPJaZgrnkpAjhBDOs3q1ubyQkZxjxyAz03E1CSFqHAk5dvR34t/Ep8TTv4lMVatSJOQIIYTzrFljGr106FCx421tpA8fdlxNQogaR0KOHcl6HAts2QLjx0NWVtnHSMgRQgjnWb3a7I/j4VGx46WNtBDCASTk2NGKgysI9g2mXb12VpdSM2gNDz8Ms2bBzp1lHychRwghnOPsWfPhU0WnqkFhyJF1OUIIO5KQY0fLDy6nf9P+uCl5Wp3ijz9ghRk9Y+/eso+TkCOEEM6xYQPk5la86QBAeLhpJS0jOUIIO5J343YSlxzHgTMHZKqas2gNzz0HDRuan88XctzdzYZzQgghHMfWdKBXr4rfx9sbGjSQkCOEsCsJOXay8uBKQNbjOM2vv5rFrc8/D2Fh5w85tWubTwqFEEI4zpo10K4dBAVd2P0utI10fHz5azGFEDWehBw7WbB3AYE+gXSu39nqUlyf1ibcRETAxInQqlXFQo4QQgjHsW0CeiFT1WwuZEPQlBRo2xb+9a8LfxwhRI0hIccOkjKS+G7Xd4zpMAZ3N3ery3F9P/0E0dEm6Hh5ScgRQoiq4K+/4PTpC2s6YNO0qQk5eXmF123eDOvWnXvs4sWQmgoLFlS+ViGEy5OQYwdzt88lIyeD2yNvt7qUmuH116FlS7jtNvNzq1Zw4gQkJ5d+vIQcIYRwvDVrzGVlR3IyM+HkycLrxo+Ha68tHnwAfvnFXEZHm1AlhBClkJBjB5/GfEqH0A5EhUVZXYrr27sX1q6Fe+4p3IOhVavC20ojIUcIIRxv9WoIDDRTyS5UyTbSBw/Ctm1w5AisWlV4nNYm5DRrZr5fuvSiyxZCuCYJORdp+4ntrI9fz8TIiShZ2O54c+aYBgJjxhRe17KluZSQI4QQzrV7N3z2GTz0EHz3nRnFcavEW4umTc2lbV2ObSqahwfMnVt4XEwMHD0KTz9t/q4vWXIx1QshXFgFtyMWZZm5eSYebh7c2ulWq0txfVrDl1/CoEHQqFHh9S1amEsJOUII4Txr1hSuv/H3hy5dYPLkyp3LNpJjCzk//2w+wOraFebNg3feMYHHFn6uusqsz1y8+OJ+ByGEy5KRnIuQlZvFF1u/YFSbUdSrVc/qclzfhg2wbx+MHVv8ej8/s5mchBwhhHAe2zSy6GhITDSbMw8ZUrlzBQaav9MHD8LZs2az55Ej4eab4dQp8zOYqWpRUVC/vnms/fvh77/t8dsIIVyMhJyLsOCvBZxMO8nEyIlWl1IzfPml2TTuuuvOva2sDmtaS8gRQghH2LTJjMB062Y2XL4YShW2kf7jD9OE4MorYfhw8/f7669N2Fm71lwPcPnl5lKmrAkhSiEh5yLMjJlJQ/+GDG051OpSXF92tpmXfdVVEBBw7u1lhZzMTMjJkZAjhBD2tmmTCTj2YtsQ9OefzfS3/v3BxwdGj4bvvzfT07QuDDlt25rNoCXkCCFKISGnknLyclh8YDE3XHIDHm6ytMnhliwxrUVvLWPtU6tWkJAAZ84Uvz4lxVxKyBFCCPtJTjb74nTtar9zNmliQs6CBTB0qNkHDcyUtcREeO45CA0tDFZKmdGc338/t820EKLGk5BTSXtO7SEjJ4PujbpbXUrN8OWXULeumbpQmrLaSEvIEUII+4uJMZf2DjmnT0N8fOFoDZi1N0FBpp308OHFu7cNGWI+4LLVI4QQ+STkVNKW41sAiGwQaW0hNUFaGsyfDzfeWPjJXkllhZzUVHMpIUcIIexn40Zzae/pajYjRhR+7+kJ119vvi8afgAGDzaXMmVNCFGChJxKijkWg7e7N22C21hdius7dMgEnX79yj6meXMzdUFGcoQQwvE2bTLrYerXt985bW2ke/Q497wPPQSjRp07mt+wIXToIK2khRDnkJBTSTHHYmgf2h5Pd0+rS3F9SUnmMjCw7GN8fMwLpIQcIYRwvI0b7TuKA+bDKjCto0vq0AF+/NE0JCipVy/YutW+tQghqj0JOZWgtSbmWAyR9SOtLqVmsIWc0rqqFVVahzUJOUIIYV9nz8Lu3fZdjwNmZGjRInjssQu7X6NGpjFNdrZ96xFCVGsScirhaOpRTqadlPU4znKhIUfrwusk5AghhH1t2WL+zto75ABccYXZ4PlChIWZeo4ft389QohqS0JOJWw5Jk0HnKoi09XAhJzERNNpx8YWckqb4iCEEOLCOaLpwMUICzOXR45YW4cQokqRkFMJMcdiAOhUv5O1hdQUFzKSA8WnrMlIjhBC2NemTWa/Glu4sJqEHCFEKSTkVELM8RiaBTYjwOc8b7qFfSQmms5p5xuNKSvkeHmV3XpaCCHEhbE1HVDK6kqMRo3MpYQcIUQREnIqIeZYjExVc6akJKhTp/gGcKVp1gzc3WHPnsLrUlJkFEcIIewlPR127nTMepzKqlfP/O2XkCOEKEJCzgVKzUplb8JeCTnOlJR0/qlqYEZrWrSQkCOEEI6ydSvk5latkOPmZvbLiY+3uhIhRBUiIecCbTu+DY2WkONMFQ05AG3aSMgRQghH2bTJXFaVpgM2YWEykiOEKEZCzgXaclw6qzldUtL5O6vZtG0Lf/1lPmkECTlCCGFPMTEQFGQ2X65KJOQIIUqQkHOBYo7FEOgTSOM6ja0upea4kJGctm0hKwtiY83PEnKEEMJ+/v4bWrasOk0HbCTkCCFKkJBzgWxNB1RV+wPvyhITL2y6GhROWZOQI4QQ9nPoUNUbxQETck6fhowMqysRQlQREnIuQG5eLluPbyWyfqTVpdQsFzqSA7B7t7mUkCOEEPahddUOOQBHj1pbhxCiypCQcwH2nt5Lek66rMdxJq0vLOQEB5svCTlCCGFfp0+bFtKNq+B0bdkQVAhRgoScC7D56GZAmg44VVqaaSJQ0ZADZjRnzx4TkFJTJeQIIYQ9HDpkLqvySI6EHCFEPgk5FyD6SDTe7t5cUu8Sq0upOZKSzOWFhpzdu01AysuTkCOEEPYgIUcIUY1IyLkAG49uJLJBJJ7unlaXUnPYQk5FW0iDaT5w4kThC7KEHCGEuHiHD5vLqjhdLSjIbAgtIUcIkU9CTgXl6Tw2Hd1Et4ZVbAM0V5eYaC4vdCQHIDraXErIEUKIi3foEHh7Q716VldyLqWkjbQQohgJORW0N2EvKVkpRIVFWV1KzVLZ6WoAGzaYSwk5Qghx8Q4dMqM4blX0rUNYGMTHW12FEKKKqKJ/qaqejUc3AtAtTEZynKoyIadZM/D0lJEcIYSwp8OHq+ZUNZtGjWQkRwhRQEJOBUUficbHw0eaDjhbZUKOh4fZkXuz6YYnIUcIIeygqu6RYyPT1YQQRUjIqSBb0wEPNw+rS6lZKhNywExZs+18LSFHCCEuTk6OCRBVPeSkpJgvIUSNJyGnAqTpgIWSksz8b3//C7tfmzaF30vIEUKIi3PkiGnJX5Wnq9naSB89am0dQogqQUJOBfyV8BepWanSdMAKiYlmFEepC7ufrfkASMgRQgCglPJRSq1XSm1RSu1QSr1odU3VRlXeI8fmfHvl5ObCmTPOq0cIYSkJORWw8Uh+0wEZyXG+pKQLn6oGxUPOhY4CCSFcVSZwmda6MxAJDFNK9bK2pGqiuoecs2fhiiugfXvQ2rl1CSEsIQtMKiD6SDS+Hr60q9fO6lJqnsqGHNt0NT8/cHe3b01CiGpJa62B1PwfPfO/5B1vRVTljUBtygo5Z8/CyJGwbJn5OSnpwjaYFkJUSzKSUwHSdMBClQ05gYFQv75MVRNCFKOUcldKxQAngMVa63UWl1Q9HDoEdetW7ZHx2rWhVq3iISc1FUaMgBUr4MYbzXW2USkhhEuTkHMeuXm50nTASpUNOWCmrEnIEUIUobXO1VpHAuFAD6VUh6K3K6XuVkpFK6WiT548aUmNVVJVbx8NZu1m0TbSublw9dWwahXMng2TJ5vrJeQIUSPI0MR5/JXwF2ezz0rTAatczLSCxx6TLjtCiFJprROVUkuBYcD2ItfPAGYAREVFyVQ2m6q+EahN0ZDz3nvwxx/w0Udw882FrwcScoSoESo0kqOUGqaU2qOU2qeUerKMY25USu3M71gzx75lWmfj0fymA2EykmMJW3e1yrjqKrj7bruWI4SovpRS9ZRSgfnf+wKXA7stLaq6qA4jOWBCTnw8xMbCU0/B8OFwxx3mtvr1wdOzcH2REMKlnXckRynlDryHeTGIAzYopX7SWu8sckwr4Cmgj9b6jFIq1FEFO1v0kWj8PP1oG9L2/AcL+9IakpMrH3KEEKK4hsDn+a9rbsA3WuufLa6p6ktNNa2Xq0vIOXIE7rnH7LH2wQeFWxC4uUF4uIzkCFFDVGS6Wg9gn9b6AIBSai5wNbCzyDF3Ae9prc8AaK1P2LtQq2w5voWOoR2l6YAVUlPN5nMScoQQdqC13gp0sbqOaqc6dFazCQuDjAz47TczXa1kMGvSREKOEDVERaarNQKKju3G5V9XVGugtVLqT6XUWqXUsNJOVN0WdGqt2Xp8K53rd7a6lJopKclcSsgRQgjrVIc9cmxsbaT79oV77z339saNJeQIUUPYq7uaB9AKGAiMAT6yzXsuSms9Q2sdpbWOqlevnp0e2nGOph7ldPppOtbvaHUpNZOEHCGEsF51CjmXXmoCziefmOlpJTVpYtbs5OY6vzYhhFNVJOTEA0XHqMPzrysqDvhJa52ttf4b+AsTeqq1rce3AtCpfieLK6mhbCFHNm0TQgjrHD5sAoNtlKQqa9oUVq6E1q1Lv71JExNwpPOmEC6vIiFnA9BKKdVMKeUF3Az8VOKY+ZhRHJRSIZjpawfsV6Y1bCGnY6iM5FgiMdFcykiOEEJY59AhE3A8XGBtqm00SqasCeHyzhtytNY5wIPAImAXphvNDqXUS0qpUfmHLQISlFI7gaXAP7TWCY4q2lm2ndhGeJ1w6vrWtbqUmkmmqwkhhPWqS/voirA1T5A20kK4vAp9LKO1/gX4pcR1zxf5XgOT879cxtbjW2WqmpUk5AghhPUOH4ZuLrJXnIzkCFFj2KvxgMvJzs1m18lddAqVkGMZCTlCCGGt7GwTclxlJKdOHfOaIiFHCJcnIacMexL2kJ2XLZ3VrJSUBO7u4OdndSVCCFEzrV8PmZnQs6fVldiPtJEWokaQkFMG6axWBSQlmc5qtt2qhRBCONeSJeZv8KBBVldiP02ayJocIWoACTll2Hp8K55unrQJbmN1KTVXYqJMVRNCCCstXgxRURAUZHUl9tOkiYzkCFEDSMgpw7YT22hXrx2e7p5Wl1JzJSVJyBFCCKskJ8PatTBkiNWV2FeTJpCQAGfPWl2JEMKBJOSUQTqrVQEScoQQwjorVpiNM10t5EgbaSFqBAk5pTiTfoa45DjprGY1CTlCCGGdJUvA1xd697a6EvuydYqTkCOES5OQU4ptJ7YBSGc1q0nIEUII6yxeDP36gY+P1ZXYl+yVI0SNICGnFNJZrYqwdVcTQgjhXEeOwM6drjdVDaBRI9MxTkKOEC5NQk4pth7fSrBvMA39G1pdSs2Vl2cWvcpIjhBCON/vv5vLyy+3tg5H8PSEhg1lupoQLk5CTim2ndhGx/odUbI/i3VSUkBrCTlCCGGFxYshJAQ6ueiMBmkjLYTLk5BTQp7OY9vxbXQMlfU4lkpKMpcScoQQwrm0Nk0HBg8GNxd9myAhRwiX56J/vSrvYOJBzmaflZBjNQk5QghhjV274OhR15yqZtO4sZmuprXVlQghHERCTgnbT2wHoENoB4srqeEk5AghhDWWLTOXl11maRkO1aQJZGTAqVNWVyKEcBAJOSXYQk770PYWV1LD2UKOdFcTQgjnWr3aLMyPiLC6EseRNtJCuDwJOSXsOLmDJgFNqONdx+pSajYZyRFCCGusWQOXXmraLLuqxo3NpYQcIVyWhJwStp/YTvt6MopjucREcykhRwghnOf4cThwAHr3troSx7KFnPh4a+sQQjiMhJwicvJy2HVql6zHqQpOnDCXEnKEEMJ51qwxl5deam0djhYSYvbLiYuzuhIhhINIyCli3+l9ZOVmScipCn76Cbp3B19fqysRQoiaY/Vq8PKCrl2trsSx3NygUSMJOUK4MAk5Rew4sQOQzmqW27ULNm+GsWOtrkQIIVzHhg1w001w7FjZx6xZYwKOj4/z6rJKeLiEHCFcmIScIraf2I5C0TakrdWl1GyzZ5tP2W66yepKhBDCdcyfD998A/36wcGD596elWWCkKuvx7Fp1EjW5AjhwiTkFLH95HZaBLXAz9PP6lJqLq1hzhyz03aDBlZXI4QQruPAAQgKMnvD9O0Lu3cXvz0mBjIzXX89jo1tJEc2BBXCJUnIKWL7ie0yVc1qa9bA33/LVDUhhLC3/fvNVLTlyyE724zo7NhRePvq1eaypozkhIebDUFPn7a6EiGEA0jIyZeZk8nehL3SPtpqs2ebueCjR1tdiRBCuJb9+6FFC+jUCVauNNOCb7sNcnLM7WvWmE0yw8KsrdNZwsPNpUxZE8IlScjJtydhD7k6V0ZyrJSdbeaLjxoFdWQzViGEsJvERDNi0aKF+blVK3j/fdPkZepUc93q1TVnqhqYNTkgzQeEcFEeVhdQVWw/sR2QzmqW+u03M1dcpqoJIYR9HThgLps3L7zuuuvM15QpEBVl3uzXlKlqUDiSIyFHCJckIzn5tp/YjoebB62DW1tdiuv59ttzF7iWZvZssyh22DDH1ySEEDXJ/v3m0jaSY/Puu+DnB9dfb36uSSM5DRqYKXsyXU0IlyQhJ9+OkztoHdwaL3cvq0txLVqbOd+vv17+cVlZ8PPPcO21ZiM6IYSozlJS4Phxq6soVNpIDpg3+m+9BUlJZvPlyEinl2YZT0/z+8tIjhAuSUJOPums5iAJCaZ7zZ495R+3erV5U3Dllc6pSwghHGnWLDMd6ppr4KefzJpDK+3fDyEhpa93HDfONHsZMcK88a9JGjWSkCOEi5KQA5zNOsuBMwfoUE9Cjt3ZpgHs3l3+XgQLF5oX18GDnVOXEEI40F/dIlg6OhK9di1cfTU0bgwzZ1q3J4uts1pplILvvjNTi2ua8HCZriaEi5KQA+w8uROQpgMOYXvxSEyEEyfKPm7hQrM5Xe3aTilLCCEcaYXXUS5rH80Pi96GH3803cwmTjSNVZKSnF/QgQNlhxwwQacmsm0IWlRODhw9ak09Qgi7kZADbDuxDYD2obJHjt0V/YSsrClrcXGwbRsMH+6cmoQQwsFuj7yd9vXa88TyZ8i6chgsWwavvGLa5HfpAtHRzismKwsOHTp3PY4wIScpyUyXtnnvPfNcHTliXV1CiIsmIQfYeGQjtb1q0zKopdWluJ6in5CV1WHt11/NpYQcIYSLcHdz59+X/5v9Z/bzQfQH4O4OzzwDK1ZAbi4MHQrHjjmnmIMHIS+v/JGcmsq2V07RD+R+/92sJf34Y2tqEkLYhYQcIPpoNF0bdsVNydNhd/HxUL++6dpTVshZuNB8mtZeRtKEEK5jWMthDG42mBeXv0hiRqK5sndv88HO2bNw773OWaNj66wmIedctr1ybCFHa1izxnz/0Udm6poQolqq8e/qs3Oz2XJsC90adrO6FNcUH28W3LZpU3rIyc6GJUvMKE5NnRMuhHBJSimmXjGVM+ln+NfKfxXe0K6dmbr2448wZ47jC7HtkSPT1c5VckPQffvMptTDh5vrfvnFutqEEBelxoecnSd3kpmbSVRYlNWluKa4ODMdoG3b0tfkrF4NycmyAagQwiVFNojkts638fa6t4lNjC284dFHzcabDz3k+EXu+/eDjw80bOjYx6mObNPVbCHHNorz2msQFgbTp1tTlxDiotX4kBN9xCz+7BYmIzkOER9fGHL+/tvMcy5q4ULw8IAhQ6ypTwghHOyVQa8A8PLylwuvdHc3LaXT0+Huux07be3AATOK41bjX/LP5eMDwcGF09XWrDF7CXXqBHfdBYsWFU73E0JUKzX+L97Goxup411Hmg44Qno6nDlTGHK0hr17ix+zcCH06VP6BnVCCOECGgc05t6oe/l8y+fsP72/8IY2bcyIwc8/w/vvO66A/ftlqlp5iraRXrMGevY0gfDOO83lRx9ZW58QolIk5BzdKE0HHMX2yVh4uHkxh+LrcuLjYetW6aomhHB5/+zzTzzdPXl15avFb3jkERgxwkxfW7/e/g+s9fn3yKnpbCEnJcVsZ3DppYXXX3UVfPKJacMthKhWavQ7e2k64GC2T8YaNYLWrc33RUPO99+by1GjnFuXEEI4WcPaDbm3273M2jKLfaf3Fd7g5gZffGHWf9xwAyQk2PeBT5wwndwk5JStUSPzodv69abVti3kgOmAd/IkzJ1rXX1CiEqp0SFnx8kd0nTAkWwjOY0agZ8fNG1avPnA3LnQsaPpNCSEEC7uiT5PlD6aExQE8+aZBgTjxpk32pWVmGjC0p9/mp+ls9r5hYebMLh8ufm5V6/C2y6/HLp2heeeM1OwhRDVRo0OORuPbASQkRxHKRpywKzLsY3kHDpkOqvdfLM1tQkhhJPZRnO+2PJF8dEcgO7dYdo007L4n/+sfCOCOXPg22/NCPmePYUhR0ZyymZrI/3tt3DJJRAYWHibmxv85z/mNWvaNCuqE0JUUo0OOdFHoqnjXYcWQfLH3yHi401Dgdq1zc+2vXK0hm++MdfddJN19QkhahSlVGOl1FKl1E6l1A6l1CPOruGffc3anFdWvHLujffdB/ffD1OnwqRJlRvRmT3bjNq4u5u1PuvWmT3IIiIutnTXZQs5u3YVn6pmM3AgXH21aRJx/LhTSxNCVF6NDjkbj26kW8Nu0nTAUWx75Ni0bWvmhsfHw9dfQ7du8umiEMKZcoDHtNaXAL2AB5RSlzizgAb+Dbi7693M3jab+OT44jcqBe++C5MnwzvvwD33QG5uxU9+4IAZIb/rLvjpJzhyBN57z/wd9vGx7y/iSoq+TpUWcgDefNNsgfDCC86pSQhx0Wrsu/us3Cy2Ht8qU9UcybZHjk3btuZywQKIjpapakIIp9JaH9Vab8r/PgXYBTQq/17290ivR8jTeby7/t1zb1TKjOQ89xx8/LEJLBU1Z465vOUWs67kyy/N+eTDpPLZRnKg7JDTujU88IBpJ719u3PqEkJclBobcnackKYDDhcfX/zFwxZy/vUvc3njjc6vSQghAKVUBNAFWFfi+ruVUtFKqeiTJ0865LGb123O6Laj+XDjh5zNOltacfDSS/D002bD0AULzn9SrU2o6d8fmjQx1113HXz3Hbz8cvn3rels06oDAwtfp0rz/PPm2LvuMrMShBBVWo0NORuP5jcdCJORHIfIzTWdgoqO5DRoYF4gDh6E3r0LX4iFEMKJlFL+wHfAJK11ctHbtNYztNZRWuuoevXqOayGR3s9ypmMM3y+5fOyD3rhBdN98qGHzt/Za9Mm02jg1luLXz96NPTrd/EFu7oWLaBvX9NooCxBQTBjhmk1fdVVkJbmvPqEEBesxoac6CPRBHgH0KKuDOM7xPHjJugUDTlKFW4KKg0HhBAWUEp5YgLObK3191bV0btxb3o06sFba98iT5fRYMDLy6yp+ftveP318k/45Zfm+Ouvt3+xNcF335mpaOdzww0waxYsW2aaEUhbaSGqrBobcjYf20yXhl1QSlldimsq2T7apm1bE3bkhVgI4WTK/MH/BNiltf6vxbUwuddk9p3ex89//Vz2gYMGwZgx8MYbsG9f6cfk5Jh9x0aMgLp1HVOwq2ve3Mw2qIixY800wt9/h2uvvbh9jYQQDlMjQ05uXi7bjm8jsn6k1aW4LlvIKbomB+Cxx+DTT83u3kII4Vx9gNuAy5RSMflfI6wq5rpLrqNJQBP+u+Y8eWvqVDNK8/DDpe+fs2QJHDt27lQ14Tjjx8Mrr8Cvv5YdPoUQlqqRIWff6X2k56TTuUFnq0txXXFx5rLkSE7nzjBhgtPLEUIIrfUqrbXSWnfSWkfmf/1iVT0ebh483ONhlh9czsqDK8s+MCwMXnwRFi40zQQOHjTXa23WiNxwA9SvD1de6ZzChdEtf03vqVPW1iGEKFWNDDlbj28FoFP9ThZX4sLi48HTExy4cFcIIaq7e6PupXGdxjz868Pk5pWzJ87DD8Orr5qRg3btYMoUGDbM7KXTo4fZ9FP2wnGuoCBzmZBgbR1CiFLVyJCz5fgW3JU7l9Rz6h5wNUt8PDRsWH6nGiGEqOFqedVi6hVTiTkWw4yNM8o+0N3dtJTevdusvXnxRVi1yjQmWLwYmjZ1XtHCCA42lxJyhKiSauQ70C3Ht9A2pC0+HvKpl8PExZ27HkcIIcQ5brjkBgZFDOLZpc+SkHaeN8xNmsC338KaNbBzJ9x/v3yYZBVbyDl92to6hBClqpF/Gbcc2yLrcRwtPv7c9ThCCCHOoZTineHvkJSRxLN/PFuxO/XqJaM3VqtTBzw8ZCRHiCqqxoWcM+lnOJx8mE6hsh7HYbSWkCOEEBegQ2gHHuj+AB9u/JDNRzdbXY6oCKXMuhwJOUJUSTUu5NiaDshIjgMlJ8PZsxJyhBDiArw46EXq+tblpRUvWV2KqKjgYAk5QlRRrh1ydu+Gp54qtlHXluNbAOhcX0KOw9jaR8uaHCGEqLBAn0Du6XYPP+7+kb/P/G11OaIiJOQIUWVVKOQopYYppfYopfYppZ4s57jrlFJaKRVlvxIvwty58PrrcOBAwVVbjm2hnl89GvhXcGdjceFsG4HKSI4QQlyQ+7vfj5ty493171pdiqgICTlCVFnnDTlKKXfgPWA4cAkwRil1Tu9lpVRt4BFgnb2LrDTbm+3t2wuu2npiK53qd0IpZVFRNcDhw+aycWNr6xBCiGomvE44119yPZ9s/oTUrFSryxHnIyFHiCqrIiM5PYB9WusDWussYC5wdSnHvQy8AWTYsb6LUyLk5OTlsP3Edpmq5miHDpkFmTKSI4QQF+yRno+QlJnE5zGfW12KOB9pPCBElVWRkNMIOFzk57j86woopboCjbXWC8o7kVLqbqVUtFIq+uTJkxdc7AWzhZxt2wDYm7CXjJwMaTrgaIcPm41APT2trkQIIaqdXuG96B7WnXfWv0Oezjv/HYR1goMhIwPS0qyuRAhRwkU3HlBKuQH/BR4737Fa6xla6yitdVS9evUu9qHPr8RIjjQdcJJDh8yGdUIIIS6YUopHej7CXwl/sWjfIqvLEeWxbQgqozlCVDkVCTnxQNHFFeH519nUBjoAy5RSsUAv4CfLmw9kZJg/Oj4+8NdfkJnJ1uNb8XDzoG1IW0tLc3kScoQQ4qLc0P4GGvo3ZNq6aVaXIsojIUeIKqsiIWcD0Eop1Uwp5QXcDPxku1FrnaS1DtFaR2itI4C1wCitdbRDKq6oI0fMZf/+kJMDf/3FluNbaBfSDm8Pb0tLc2lam+lq0nRACCEqzcvdiwe6P8Bv+38r2N9NVEEScoSoss4bcrTWOcCDwCJgF/CN1nqHUuolpdQoRxdYabapakOHmstt29hybIusx3G0U6fMKJqM5AghxEW5r/t91PKsxdTVU60uRZTFFnJOn7a2DiHEOSq0Jkdr/YvWurXWuoXW+tX8657XWv9UyrEDLR/FgcKQc9ll4OHBoT9/IT4lnsj6kZaW5fIOHTKXEnKEEOKiBPkGcWfXO/lq+1ccTjp8/jsI55ORHCGqrItuPFBl2UJORAQZLSLYsfRr2gS34fYut1tbl6uTPXKEEMJuHu31KFpr3l73ttWliNJIyBGiynLtkOPnR5xK4TffeC45rvn11l8J8g2yujLXJiM5QghhN00Dm3JTh5v4cOOHJGYkWl2OKMnLC/z9JeQIUQW5dMjJDWvI8DkjiKmXS9PTuUS4B1tdles7dMh0tAsJsboSIYRwCf/o/Q9Ss1L5MPpDq0sRpbmYDUHnzoVbb7VvPUIIwMVDzpE6sP3Edq6+7hlz3c6d1tZUExw6ZKaqKWV1JUII4RIiG0QypPkQpq2bRmZOptXliJKCgysfcj77DL76CvJk01ch7M2lQ87ROm7U9alL5yFjzXX5m4IKBzp8WKaqCSGEnT1+6eMcSz3G/N3zrS5FlFTZkJOXB2vXmsuUFPvXJUQN55ohR2s4coRD/rk0DWwKzZqBn5+EHGeQjUCFEMLuhjQfQqPajZizfY7VpYiSKhty9uyBpCTzvbSgFsLuXDPknDoFWVns9U2naUBTcHOD9u3LDjlJSfDBB5Cb69w6XU1WFhw9KiFHCCHszN3NnZs73MzCvQs5nS5viKuUyoactWsLv5eQI4TduWbIyW8fvcPzDE0C8t9wd+gA27aVfvzMmXDffbBokZMKdFFHjphRNGkfLYQQdje241iy87L5due3VpciigoOhjNnLvyDUgk5QjiUS4ecfb4ZZiQHTMg5fhxOnjz3eNsfmi+/dFKBLkraRwshhMNENoikbUhbZm+bbXUpoqjgYPMBX2Lihd1v7VoIDzffS8gRwu5cOuTE1zF7DAAm5ADs2HHu8baQM3++LP67GBJyhBDCYZRSjO04lhUHV3A46bDV5Qgb24agFxJUUlLMFPorr7zw+wohKsRlQ45WimP+FE5X69jRXG7aVPzYY8fg4EEYPRrS0+GHH5xbqys5nP+iK9PVhBDCIcZ0GAPAV9u/srgSUcAWci5kXc6GDaar2vDh5mcJOULYncuGnLSg2uS4UzhdrWFDaNMGFi8ufuy6deZy8mTThU2mrFXeoUPmj72fn9WVCCGES2oR1IJe4b2Ys026rFUZQUHm8kJCjm0GSb9+UKuWhBwhHMBlQ87pIF+83b0JrRVaeP0VV8Dy5ZCRUXjdunXg4QHdupldh3//3SygFxdO2kcLIYTD3dLhFrYc38KOE6VMvxbOV5mRnLVrzQevQUHmS0KOEHbnsiHnWIA7TQKaoJQqvH7oUDMl7c8/C69btw46dwZfXxg71gwfz53r/JpdweHDMlVNCCEc7Mb2N+Ku3KUBQVVxoSFHaxNyevUyP0vIEcIhXDbkHPTPKWw6YDNgAHh6FraKzs2F9euhZ0/zc5s20L07fPGFc+t1FTKSI4QQDlffvz5DWw5l1pZZ5ObJ/m6WCwgw+/FVNOT8/bfp9HrppeZnCTlCOITrhZz0dDh9mn0+aYXrcWz8/aFPH/jtN/Pzrl2Qmlr4aQqYKWsxMWVvHCpKl5xsNlWVkCOEEA43ofME4lPiWXJgidWlCDc3E1QqGnJs63FkJEcIh3K9kJO/nma3d2phZ7Wihg6FLVtMVzXbHxrbSA7AzTebP1jff++EYl2IdFYTQginGdVmFEG+QcyMmWl1KQLMlLWKhpw1a0yzgfbtzc8ScoRwCNcLOUX3yCk5kgOm+QCYLmvr1kHdutCqVeHtoaHQuvW5raZF+WSPHCGEcBpvD29u6XAL83fP50z6GavLERcSctauNVPjPTzMz7aQo7Xj6hOiBnLdkFObc9fkAERGQr16Zsra2rVmFKdocwIwjQi2bHF8ra5EQo4QQjjV7V1uJzM3U/bMqQoqGnIyM837i6IzSIKCICsL0tIcV58QNZDrhpw6lD5dzc0NLr8cFi6EHTuK/6Gx6dwZYmMhMdGhpbqUw4fB3d3sRySEEMLhujToQqf6nWTKWlVQ0ZCzZQtkZ5uRHBvbPjsyZU0Iu3LJkJPp40mKN4TXCS/9mCuuMH+MtC7edMCmc2dzuXWr4+p0NXv2QKNGJugIIYRwOKUUt0feTvSRaLafkGY5lqpo44HoaHMZFVX8viAhRwg7c8mQczrIl7A6jfBy9yr9mMsvL/y+R49zb7eFHJmyVjHHjsFPP8HIkVZXIoQQNcrYjmPxcPNg5mYZzbFUcLDp7pqeXv5xGzaYKfNFp3bbQs6FbCYqhDgvlww5xwLcSp+qZhMWBh07mgYDtj8uJW8PDpaQU1Hvv2+G3ydNsroSIYSoUerVqsdVra/ii61fkJ2bbXU5NZdtQ9DzjcZER5tRnKJrgWUkRwiHcMmQE1urlI1AS/r0U5hZxidfSknzgYpKSzMhZ9So4l3qhBBCOMUdXe7gZNpJfv7rZ6tLqblsIae80ZizZ2HnzuLrcUBCjhAO4lohR2v0kSOlbwRaUlQU9O5d9u2dO5sNQXNy7Fujq/niC/NHffJkqysRQogaaWjLoTSq3YiPN39sdSk1V0VCzubNkJdXfD0OSMgRwkFcK+ScOoXKzuawf17509UqonNnyMiAvXvtU5srysuDt94yf7D79bO6GiGEqJE83DyYEDmBX/f9SlxynNXl1EwVCTmlNR0A8PUFb28JOULYmWuFnPNtBHohpPnA+f3yi+mqNnnyuXsNCSGEcJqJXSaSp/P4LOYzq0upmSoScjZsMF1IS261oFThhqBCCLtxrZBz5AhQzkagF6JdO7MbsYSc0mkNU6dCeDhcf73V1QghRI3WvG5zBjcbzCebPyFP51ldTs1jCznlbT0RHX3uehwbCTlC2J1rhZz8kZwjtcvYCPRCeHuboCMh51w5OXDnnbB8OTz+OHh6Wl2REELUeHd0uYPYxFj++PsPq0upeXx84I47TCOeX3459/bERPjrr3OnqtlIyBHC7lwu5OQpSK8XQB3vOhd/Pumwdq60NBg92nSne+45ePhhqysSQggBjG43mro+dflk8ydWl1Iz/d//mfcNt94KsbHFb9u0yVyWNZITHCwhRwg7c62Qc+QISXW8aRQUYZ/zde5spsCdOmWf81V3yckwZAgsWGA+rXrpJVmLI4QQVYSPhw+3dbqN73d9T0KabCzpdL6+8O23kJsLN9wAmZmFt9maDnTrVvp9ZSRHCLtzrZATH89Re6zHsZHmA8XNnQtr1pjL++6zuhohhBAl3Nn1TrJys/hw44dWl1IztWwJn39uQs3dd5uNssE0HWjevHDtTkkScoSwO5cKOblxhzngl0mXBl3sc0IJOcUdOABeXtJoQAhRLSmlPlVKnVBKbbe6FkfpWL8jV7a6kv+s+Q8pmSlWl1MzXXMNvPACzJpltleIjTWhp6z1OGBCTnq6+RJC2IVrhZz4w8TVhm4NyxgOvlChodCggYQcm0OHoHFjcHOp/2yEEDXHZ8Awq4twtBcGvMDp9NO8u/5dq0upuaZMgW++gV27IDLSBJ2y1uNA4YagZ844oTghagbXebeamYlXQiJHakO3MDuFHJDmA0UdPAhNLrJrnRBCWERrvQJw+TlB3Rt1Z3jL4fxnzX9IzUq1upya64YbYPNmaN3a/HzppWUfaws5MmVNCLtxnZBz9CgAZ+sFEFY7zH7nbd4c4mQHacCM5DS103onIYSogpRSdyulopVS0SdPnrS6nEp7YcALJKQn8N7696wupWZr3hxWrYK1a6FPn7KPk5AjhN25TsjJ3wjUv3kb+543NNTsYJyTY9/zVjfZ2eY5lpEcIYQL01rP0FpHaa2j6tWrZ3U5ldYzvCfDWg5j6pqpMppjNS8v6Nmz/GMk5Ahhdy4TctIP7gegQWs7TlUDE3JA2kjHxUFenozkCCFENfHCgBc4lXaK9ze8b3Up4nwk5Ahhdy4Tco7sWg9A8/Z97XtiW8g5ccK+561uDh0ylzKSI4QQ1UKv8F4MbTGUN/58g8SMRKvLEeWRkCOE3blMyDlzYAcZ7tCp3UD7nlhCjnHwoLmUkRwhRDWllPoKWAO0UUrFKaXusLomR/vX4H9xOv00b/75ptWliPL4+4OHh4QcIezIZUJO1qG/ORboTsM6dmw6ABJybGwjOY0bW1uHEEJUktZ6jNa6odbaU2sdrrX+xOqaHK1Lwy7c0vEWpq2dxpGUI1aXI8qilGwIKoSduUzI8Th6nLMhAfY/sYQc4+BBqF8ffHysrkQIIcQFeHnQy+Tk5fDishetLkWUR0KOEHblEiEnJTOFwNPp6DA7j+IABAaaIWQJOTJVTQghqqHmdZtzb9S9fLL5E3af2m11OaIsEnKEsCuXCDkxRzfTKAX8Ilra/+RublCvnoScQ4ek6YAQQlRTz/Z/Fl9PX5754xmrSxFlkZAjhF25RMjZ9tcqamVDSMvOjnmA0NCaHXK0lo1AhRCiGgutFcrjlz7O97u+Z+ORjVaXI0pzISHn9GmzrYMQokwuEXJid60BoE7zto55gJoeck6dgvR0GckRQohqbFKvSQT6BPLKylesLkWUpqIh59AhaNQIBg+G2FiHlyVEdeUSISdh7xbzTaNGjnmAmh5ypH20EEJUewE+ATzS8xHm757P1uNbrS5HlBQUBCkpkJ1d/nH/+x9kZMD69dCxI3z8sZlxIYQoptqHnJTMFPLiDpsfHNF4ACTkSMgRQgiX8EjPR6jtVZtXVshoTpVj2xD0zJnyj1uwAFq2hJ07oUcPuOsueOQRx9cnRDVT7UPOjpM7aJiS/4OjQk79+nD2rPmqiWx75Mh0NSGEqNbq+tbloR4P8e3Ob9l5cqfV5YiibCGnvClraWmwdClceaX54HHxYrjpJvjsM8jKckqZQlQX1T7k7D+9n0YpkFM3AHx9HfMgtr1yTp50zPmruoMHzW7MdetaXYkQQoiL9Oilj+Ln6cerK1+1uhRRVEVCzh9/mKlqV15pfnZzMyEnJQXWrHF8jUJUI9U+5Bw4c4BGyeDWqLHjHqSmbwhqax+tlNWVCCGEuEghfiHc3/1+5m6fy55Te6wuR9jY3mvs31/2MQsWQK1a0L9/4XWDB5v9/H791bH1CVHNVPuQs//MfiLSPHFzVNMBuPiQc/as+eSlupKNQIUQwqU8dulj+Hj48PQfT1tdirDp3Nm81n72Wem3a21CzuWXg7d34fV16kCfPrBwoVPKFKK6cImQ0yhFOa6zGlx8yBk2zCwMrK4OHpT1OEII4ULq+9fnqb5P8f2u71kWu8zqcgSYqWd33WWmpO3de+7t27fD4cMwYsS5tw0bBlu2wJEjjq9TiGqi2oec2JP7CE7OdmzIqVfPXFYm5OTmwoYN8Msv1XPjrrNnISFBRnKEEMLFPHbpYzQJaMKkXyeRm5drdTkCYOJEcHeHjz4697YFC8xlWSEH4LffHFebENVMtQ45adlp5B4/hluedlxnNQA/P7PwvmTIOXzYLPYrz99/Q2amWUi4Y4fjarwYmZmlf2oEhZ3VJOQIIYRL8fX05c0hb7Ll+BZmxsy0uhwB0LAhjBoFM2ea1+aiFiyAyMjSP9Tt3BkaNJB1OUIUUa1DzoEzB2huayfv6OlUJffK0RouvRSefbb8++3aVfj98uWOqa0icnPNhmFpaefe9tJL0L596cPc0j5aCCFc1o3tb6RP4z4888czJGcmW12OALjnHjh1CubPL7zu9GlYvbqwq1pJSpnRnN9+g5wcp5QpRFVXrUPO/tP7aW/r6ty+vWMfrGTIiY83X9u2lX+/3bvNZUgILFvmsPLOa8kSM9f37beLX5+TA59+anZYnj373PvJRqBCCOGylFJMGzaNE2dPyAahVcXll0NEBHz4ofk5Lw/efddclhVywIScM2fMFHkhRPUOOQfOHKD9CdD+tZw/krN1q7ksr9UjmJGc+vXNHNoVK8wIkBVWrjSXH3xgRnVsfv0Vjh2D2rXh88/Pre/gQTM/uGFD59UqhBDCaaLCorg98nbeWvsW209st7ocYWtAsHSp6bQWFQUvvACXXQY9epR9v8svN/eVKWtCABUMOUqpYUqpPUqpfUqpJ0u5fbJSaqdSaqtS6nellFM+9t9/Zj+Rp9yhfQfH7+ESGgrHjxf+vGWLuTx8+Nx5s0Xt2gXt2sGAAWYz0aLT15xp1Srw8THTz37+ufD6mTPN7/baa2bN0KZNxe936BCEh5se/EIIIVzSm5e/SYB3APf+fC95uho2yXE1t99uXndvv91MXZszx8zIcHcv+z5BQdCz54WHnMREeOAB+PHHiypZiKrmvCFHKeUOvAcMBy4BxiilLilx2GYgSmvdCfgWeNPehZZm/5n9tD+pUB06OP7BQkNNSLF1SLON5GhtmguURmszXa1dOxg40FxnxZS1zExYtw7uvNMsWHzvPXP9yZPw009w220wdqzpuz9rVuH9UlPNOqKWLZ1fsxBCCKcJ8Qvh35f/mz8P/8mnmz+1uhzRsCH897/w+uuwZw+MGVOxD3OHDTPT1Q4frtjjxMSYkaL334ebb4aNGy+qbCGqkoqM5PQA9mmtD2its4C5wNVFD9BaL9Va21a0rwXC7Vtm6U4f3ENwSo7j1+OACTm5uWa+K5iRnPr1zfdlTVk7ftx8QtK2LTRrZkZErGg+sGmT2Yx00CCzoHHxYvjrL7MGJyfHfFJUt67p6DJnDmRlmfs9+STExcGUKc6vWQghhFNNiJxA/6b9eWLxE5w4W8l94YT9PPQQ/POf4Otb8fuMGweenhV73f7kE+jVy7w/+Okn8z5n9OjK7wkoRBVTkZDTCCj6kUBc/nVluQModdtdpdTdSqlopVT0yZMnSzukwnLzcqm9L7/zl7NCDpj/+dPTzScr11xjrtu3r/T72KamtWtnPoEZMMCEHGevy1m1ylz26WPm+Xp6wvTppuFAjx6Fz9/48WZYfOFCU+d775k/sn37OrdeIYQQTqeU4oMrPyA1K5XHf3vc6nJEZUREmKlnn31W/rYV06eb2R19+5oPQq+6Cn74wczwuPFG04xIiGrOro0HlFK3AlHAv0u7XWs9Q2sdpbWOqmfbYLOSDicfps3x/AX0zpquBibk7Nxppq0NGWIW7Jc1klM05ICZsnb8uAlIzrRyJbRubUaeGjSA664zf+C2bTOjODZDh5pjPvgA7rgDmjc3a3WEEELUCO3qteOJPk/wxdYvmLJsCtqqZjmi8p55xrw3efKcJdTGxo0waRIMHw6LFhW+v+na1WxCunw5/OMfTitXCEepSMiJBxoX+Tk8/7pilFJDgGeAUVrrclbi28f+0/vpcAKy6/g7p/NX0ZBjazrQuTO0aFH2SM7u3WYTUdvGXQMGmEtnTlnLy4M//yw+GvPAA2adjo+PmYNr4+Fh1ub8+qsJbp98ArVqOa9WIYQQlnt+wPNMiJzAi8tf5NYfbiUjJ8PqksSFCA42Aefnn01X16ISE+GGG8wHml98cW4jg1tvNe8R3n67cO2xENVURULOBqCVUqqZUsoLuBn4qegBSqkuwIeYgOOUyZy29tG57do6vrMaFA85W7eCn58Z6WjZsvyRnLZF6mvZ0gQyZ4acXbvMJmJFQ06fPubnCRMgMLD48RMmmMv77y9sliCEEKLG8HL34tNRn/LqZa8yZ9schswawqm0U1aXJS7EI4+YD1ifeKJwirzWMHGiaUrw9dcmDJXm5ZchIACee8559QrhAOcNOVrrHOBBYBGwC/hGa71DKfWSUmpU/mH/BvyBeUqpGKXUT2Wczm72n95H+5Pg1bmrox/KCA42YcU2ktOxo/kEpEUL012t6N4zNrb20Ta2dTnLljlvXY5tPU6/fsXrWLnSTFkrqWNHiI6GadOcUp4QQoiqRynF0/2e5uvrvyb6SDT9ZvYjPvmcSRyiqvL1hZdeMp1Ve/Qwe+z07WvW3bzxBlx6adn3rVsXHn/cNCNYv955NQthZxVak6O1/kVr3Vpr3UJr/Wr+dc9rrX/K/36I1rq+1joy/2tU+We8eAl/7yA4HdycsR4HzFSu4GCzpmbLFujUyVzfsqVZoFeyXWNKCsTHFw85YEZHjh49/yai9rJypRmWbtGi4vfp1s00JxBCCFGj3dj+Rhbduoj45Hj6zezHgTMHrC5JVNT48WZEJyDAdFLNzYXJk+HRR89/30ceMe95nn3W8XUK4SB2bTzgTO47d5tvnBVywExZ27zZtJHu3NlcZwsPJdfl7M6vr23b4tfbRlRKzpN1lFWrzGM6Y0qfEEIIlzMgYgB/jP+DpMwk+n7alx0nyunaJaoOd3czK2PJEvOeY+1a+M9/KvZ+wNa4YPFia7a+EMIOquU29lprAvbHmR+c0T7aJjS0MJzYRnJsIWf/ftNtzaZkZzWbdu0gJMSMsEyc6Nh6Dx+Ggwcr9qmNcCnZ2dnExcWRkSELhoXh4+NDeHg4njJKKyohKiyK5ROWc8UXVzB41mC23LuF+v71rS5LONL995sNSZ97zgQd+bBUVDPVMuQkpCfQ8kgmaYG18LM1BHCG0FDTrQwKQ054OHh7nzv9bNcuM8Wt5DQxpcy8WGeM5JS2HkfUCHFxcdSuXZuIiAiUvDDVeFprEhISiIuLo1mzZlaXI6qpDqEdWHTrInp83INx88excOxC3FS1nRAizsfPz7SjfvBBs53E009L0BHVSrX867T/9H7an4C01k5+sbYFqogIM8cVwM0NmjUrfbpaq1alr23p3x8OHDBrdhxp7VrTAtoWyESNkZGRQXBwsAQcAZhF5MHBwTKyJy5ax/odmTZ0Gr/t/41//1nqlnjCldx9t9lq4tlnzRof+RsiqpFqGXIOnN5P+5OgOnR07gPbQk7J0FBaG2lb++jS9O9vLleutG99Je3YYabzeVTLATtxkSTgiKLkvwdhL3d3u5sbLrmBZ/54hjWH11hdjnAkT0+YM8d0avviC9Ol7fffzddvv8H27VZXKESZqmXIOfnXZgIyoXbXXs59YFvIsTUdsGnRwoQcW1vorCwzslNyPY5N585mk1BHT1nbuRMuucSxjyFEKRISEoiMjCQyMpIGDRrQqFGjgp+zsrLKvW90dDQPP/zweR+jd+/e9ipXCHEBlFLMuGoGjQMaM+a7Maw4uALtrG0RhPMpZdblzJsHMTFm/fGQITB0qPnQ9//+z+oKRVWQk2M2m42Lgz17zHthi1XLj/gvOWH+mHp16uLcBy5vJOfsWdNeukED2LTJtGosK+R4eJgNOR05knPmjGlVLSFHWCA4OJiYmBgApkyZgr+/P48//njB7Tk5OXiUMcIYFRVFVFTUeR9j9erVdqnVmXJzc3EvucO4ENVQoE8g31z/DUO/HMqAzwbQLqQd93S7hzEdxxBay4lrZYXzXH899OxpPsR1dzdf//kPPPwwHDsGr7xyYWt28vLM+5SUFDO1vlYtswRg/34z5X/vXnNMYKBZIhAWBt27m+ZNYN5nrV8PixaZD5nbtTPveVq3Bh+fyv+eZ8+a91BBQWZd0sU6fRpiYyEy0vx+rubwYXjhBZg1q/iekSEhMG4c3HGHZe9Fq2XIGZLWwHzjzM5qYPa4uftuuOKK4tcXbSNdv76ZuxoUBCNHln2ufv3McQkJZe86fDFs3d0k5IgqYsKECfj4+LB582b69OnDzTffzCOPPEJGRga+vr7MnDmTNm3asGzZMqZOncrPP//MlClTOHToEAcOHODQoUNMmjSpYJTH39+f1NRUli1bxpQpUwgJCWH79u1069aNL7/8EqUUv/zyC5MnT6ZWrVr06dOHAwcO8PPPPxerKzY2lttuu42zZ88C8O677xaMEr3xxht8+eWXuLm5MXz4cF5//XX27dvHvffey8mTJ3F3d2fevHkcPny4oGaABx98kKioKCZMmEBERAQ33XQTixcv5oknniAlJYUZM2aQlZVFy5Yt+eKLL/Dz8+P48ePce++9HDhg9iGZPn06v/76K0FBQUyaNAmAZ555htDQUB555BFn/JMJUa7ujboTNzmOr7d/zYcbP2TSoklMWjSJrg27MqzFMK5ocQU9w3vi43ERbzhF1dK4sfmy6dXLdGF77TUTdN5+28xUKcv69WYz0q1b4dCh8j/tV6r0jdNbtIA2bcxGpwkJhcHB1hjKxweuvBJuuglGjDDhqaT0dFNDRoap4exZ2LABli41lzk5heeqX9/MwImKMiGrbVvTdOp8SwH++su08P7sM/N44eFmfdMtt5jAU12mEGdnmyCanGwubc+z1vDVV/DOO+a6u+4ya9Fr1wYvL/j5ZzPK99//moZbf/zh9D0Yq2XIwcPDfJoQFOTcx61bFz788Nzri7aRTkkxc1Xfftt8+lAW27qcP/+EUQ7YO3XnTnMpIafGm/TrJGKOxdj1nJENIpk2bNoF3y8uLo7Vq1fj7u5OcnIyK1euxMPDgyVLlvD000/z3XffnXOf3bt3s3TpUlJSUmjTpg333XffOW2QN2/ezI4dOwgLC6NPnz78+eefREVFcc8997BixQqaNWvGmDFjSq0pNDSUxYsX4+Pjw969exkzZgzR0dEsXLiQH3/8kXXr1uHn58fp06cBGDt2LE8++SSjR48mIyODvLw8DpfcDLiE4OBgNm3aBJipfHfddRcAzz77LJ988gkPPfQQDz/8MAMGDOCHH34gNzeX1NRUwsLCuPbaa5k0aRJ5eXnMnTuX9bIDuahC/Dz9uL3L7dze5Xa2Ht/K//b8j0X7F/HGn2/w2qrX8HL3omejnvRv2p+rWl9Fj0Y9ZH2YK3F3hw8+MEHg5ZfNup1+/WDYMBMI6tc3s2Di4uD55+Gnn8wn/JddBtdeaxo31akDaWkmaOTkmOvatjXvrTw9zfuqpCT4+28TbNatM+9xRowwX1dcYUZc9u41169cCd9+C999Z67v3dt89eljQtH338Mvv5jHLPm7dO8O//iHaTB1+rQ5Pj7ezND56afix4aHm9GjIUPg8svNvo27dpm1Sr/8YvYn8vKCW281b/J/+MGEnqlTTS3PPmum/FXV/x9WrYLXXze/S1nTUZWCsWPNv31ERPHbxo+HEyfMfxOHDlmyyXz1DDmTJpmvqiIiwnySsGcPvPmmmb52773l36d7d9N6esUKx4UcX19o2tT+5xaikm644YaC6VpJSUmMHz+evXv3opQiOzu71PtceeWVeHt74+3tTWhoKMePHyc8PLzYMT169Ci4LjIyktjYWPz9/WnevHlBy+QxY8YwY8aMc86fnZ3Ngw8+SExMDO7u7vz1118ALFmyhNtvvx2//OkKQUFBpKSkEB8fz+jRowGz90xF3HTTTQXfb9++nWeffZbExERSU1MZOnQoAH/88QezZs0CwN3dnYCAAAICAggODmbz5s0cP36cLl26EOyIkV8h7KBT/U50qt+JZ/o/Q1JGEisOrmDloZWsOLiC11e9zqsrXyW8TjjXtr2We6PupV29MqZ0i+pFKdOY4IorTBD49Vd44olzjwsIMFPaHnmk/NGe0u4XEABNmsCAAWUf17Gj+brpJvNB84oVJtCsWmUe1zYC0aCBeQM+dKgJWF5e5qttWzMKUZbkZLMh/L59ZvpZbCxs3Ai2qdg+PoXd59q2NaHu/vtN0AO4/XYTmmbPhn//G4YPh27dYMIEMzOpXTtzbFaWmS6XlGTqCw01ocpGaxMIDx40wS82tjAg5uSYKWNFQ4mHhwkYHh7QqJF5rLZtz53Sl5ZmQtrWrfDJJ+ZD+OBgeOwxE+hq1zb/bkVHsNq2Lf/D9NBQc3+LVM+QU9V4eZn/+aZPN4uuvv/eXFceHx/o0cNx63J27jT/w7ji/E9xQSoz4uIotYpMG3juuecYNGgQP/zwA7GxsQwcOLDU+3h7exd87+7uTo5tGsEFHlOWt956i/r167Nlyxby8vIqHFyK8vDwIM/2AgrntGou+ntPmDCB+fPn07lzZz777DOWLVtW7rnvvPNOPvvsM44dO8ZER28gLISdBPgEcFWbq7iqzVUAJGYk8r89/+O7Xd/x4cYP+TTmU+bdMI9hLYdZXKmwm759zdebb5rRjz17zCf5J06YN93jxpkZMc7g7g6DBpkvMAFl/XozstOrV+XeG9WpY0JWyaAVFweLF5vA06WLGdVp0qT0cwQHmzVM995rRjhefx0eeqjwdk9PMz2sKDc3qFfPvG9MSTFfZXwoWECpwul+pY3CuLlBw4bmeXJzM+EoPr7w2KZNzTS0iRNLn+5XTUjIsZeWLc3QZN++cM01FbtP//7mP/DU1Av7VKMidu4s/xMPISyWlJREo0aNAPjss8/sfv42bdpw4MABYmNjiYiI4Ouvvy6zjvDwcNzc3Pj888/JzV84efnll/PSSy8xduzYgulqQUFBhIeHM3/+fK655hoyMzPJzc2ladOm7Ny5k8zMTNLT0/n999/p27dvqY+XkpJCw4YNyc7OZvbs2QXPweDBg5k+fTqTJk0qmK4WEBDA6NGjef7558nOzmbOnDl2f56EcIZAn0Bu63wbt3W+jSMpR7hyzpWMnDOSD0Z+wJ1d77S6PGFvjRqZr6qiTh0zrcwRwsPNKM3tt1f8Pl5eZkH+xIkmXOzaZb7i4syoVd265jI52TRnOHoUMjPN71G7trmtaVMztc+2d6OHR2FoKSovz4SirCwzbWzHDvN1+LC5LS/PBKLmzc0oT4cOZm2NCzTJkZBjL7aQM3VqxedX9usHr74Kq1ef28zgYiQnm/94ZT2OqMKeeOIJxo8fzyuvvMKVV15p9/P7+vry/vvvM2zYMGrVqkX37t1LPe7+++/nuuuuY9asWQXHAgwbNoyYmBiioqLw8vJixIgRvPbaa3zxxRfcc889PP/883h6ejJv3jyaN2/OjTfeSIcOHWjWrBldupTd+fHll1+mZ8+e1KtXj549e5KSkgLA22+/zd13380nn3yCu7s706dP59JLL8XLy4tBgwYRGBgondmESwirHcaKCSu4Yd4N3PW/uzhw5gBTBk7By/08MyCEcDVKmZAUHm5GgBzBzc0sj/D2NiHG2U27LKSs6m0fFRWlo6OjLXlsh9i/38zVvP76it8nNdXMDb32WtN6z17WrTPDsfPnw9VX2++8otrYtWsX7cpqYV6DpKam4u/vj9aaBx54gFatWvHoo49aXdYFycvLo2vXrsybN49WrVpd1LlK++9CKbVRa33+nt01kMu9TlUx2bnZ3L/gfj7e/DFtgtswbdi0c6avpWalsuvkLnac3EFKZgp3dL0DP087tPUVQlQblX2dkpEce2nRorDLWkX5+5vhyvffN+0XSyymrjTprCYEAB999BGff/45WVlZdOnShXvuucfqki7Izp07GTlyJKNHj77ogCNEVePp7smMq2ZwTdtreHTRowyfPZyhLYYSVjuM/Wf2s//0fuJT4ovdZ8amGcy7YR5tQ9paVLUQorqQkRyr/f23mer2+OOmd7w9/OMfpjd5aur5+7gLlyQjOaI0MpJzYeR1ynmycrP4v3X/x2urXsPb3ZsWQS1oUbcFrYJa0T60Pe3rtWf/mf3c9sNtZORk8NFVH3Fzh5utLlsI4QQyklNdNWtmpqt9+KHpmV5e+8KK2rnTbJQlAUcIIUQ14OXuxWO9H+Ox3mW3m20V3IrN92zm5m9vZsx3Y/jvmv9yRYsruKLFFYT4hbD68GpWH17NXwl/MazlMMZ3Hk/jgMZlnk8I4drkXXBV8NhjZuOqTz81/eNLOnzYNCgYOdJ8nc/OnWZNjhBCCOFCwuuEs3T8Ut5e9zY/7P6hYP8dm2DfYJoGNuW5pc/x/NLnubzF5TSu05ijqUc5knIEfy9/nuzzJCNajSjYlPRw0mE+3Pgh9fzqcV/3+6QBghAuQqarVRV9+5o2gnv3Fo7A5Oaa9TpPP22mnoHZ0Orpp8vu4Hb2rFnr89JL8NxzzqldVDkyXU2URqarXRh5nar6kjKSWBq7lMSMRC4Nv5TWwa1RSnHgzAE+j/mcL7d9SVp2GmG1w2jo35Bdp3Zx4MwBejfuzSM9H2HB3gXM2TaHPJ1Hns6jdXBrpg2dxvBWw4s9Tm5eLr///Tuzt80mNSuVPo370LdJXyIbRJKenU5iRiKJGYnk5Jk9upRShNcJJ7RWqBVPixAuRaarVXePPWamrb3zDjRuDAcOmE1F1683u/L+979mNOfZZ2H7drMbrV8pHWZ27zaX0nRACCGEiwvwCeCattecc33zus15cdCLvDjoxWLXZ+dm8+nmT3l5xcvc9O1N+Hn68UD3B3i016PsPLmTSYsmMWLOCPo26UuTgCbU8jQt5RfsXcCRlCME+gQS5BvE97u+P29tXu5e3N31bp7q9xRhtcPI03ksj13OvJ3zSM5Mpo53Hep416GBfwO6NOhCZINIAnwCLur5SM9O52DSQdoEtykYqXIWrbXTH1OI8kjIqSpGjTINCB4rMh+5SROYPRvGjDEjN19+CR07mpGczZtNs4KxY8HXt/A+0llNVAGDBg3iySefZOjQoQXXTZs2jT179jB9+vRS7zNw4ECmTp1KVFQUI0aMYM6cOQQGBhY7ZsqUKfj7+/P444+X+djz58+ndevWXJL//8Dzzz9P//79GeKojeCEENWGp7sn90Tdw7jO41gau5SejXoS7BcMQNPApgxuPpi3177NV9u/Yn38elKzUsnIyaB/0/7c1uk2RrYeiY+HD0dSjrDq0Cp2ntxJba/a1PWtS6BPIJ5unmg0WmsW7F3ABxs/4OPNH3N1m6v58/CfxCXHUcuzFvX965OcmUxSRhLZeYW717eo24JmdZsRXiec8Nrh5Ok8jqQe4WjKUc5knEGhcFNueLh50DG0I/2a9qNfk34cTT3Kp5s/5avtX5GYkUin+p14uMfD3NLxFnw9fYs9B1m5WcQci2HnyZ3U86tH44DGNK7TmECfwPOGlLTsNNKz06nlVQtvd28S0hP4ac9PfL/rexYfWIy/lz9NA5oSERhB4zqNaVSnEY1qN6Kub10S0hI4cfYEJ86e4FTaKU6ln+JU2ilC/EIY12kcV7W5SqYKCruS6WpVyV9/mZDSvLlpSFBWE4KFC+Gpp2DLFggJgfvug4cfNt8/9ZTZkDQtDTw9nVu/qDKsnq42Y8YM1qxZw8yZMwuu69WrF2+++Sb9+/cv9T5FQ05ZKhJyJkyYwMiRI7n+QvasqmJyc3MdsvGnTFcDpdQw4G3AHfhYa/16WcfK65S4WAfOHODlFS/z3c7vGBAxgLEdxzKqzahie/0cTz3O5mOb2XR0EzHHYjiUdIi45DiOph5FoWjg34Cw2mEE+QYBkKfzSM9JZ/PRzZzNPltwHh8PH65rdx1RYVHMjJnJ1uNbCfINon299tTyqkUtz1qcTDvJ+vj1ZORknFOrQuHv5Y+/lz/BfsG0DGpJq6BWhNUOY+fJnayLX8f2E9vJ03kAuCt38nQeGk1EYAQjW40kV+dyMOkgsYmxHE46TEpWyjmP4+XuRT2/eoT4hRDsF8yeU3uIT4kn2DeYm9rfRJeGXWgV1IoWQS1ISEtg24ltbDu+jYNJB0nMSCQpM4nUrFRqe9UmyDeIur51aRrQlPb12tM+tD3N6zbHXbnjptxwd3PHw+3cz/PTstM4lnqMiMAI3JRbhf4tc/NyyczNJD07nfScdNKz0/Fw8yCsdhjeHt4VOkdlRB+J5v/W/x+pWancHnk7w1sOx92tZm0MXdnXKQk51ZXWsGwZvPUW/Pwz1KoFDz5oNgI9fhx27LC6QmEhq0PO6dOnadu2LXFxcXh5eREbG0v//v05ePAg999/Pxs2bCA9PZ3rr7+eF18000mKhpyIiAiio6MJCQnh1Vdf5fPPPyc0NJTGjRvTrVs3Hn/8cT766CNmzJhBVlYWLVu25IsvviAmJoaRI0cSEBBAQEAA3333HS+//HJB6Pn99995/PHHycnJoXv37kyfPh1vb28iIiIYP348//vf/8jOzmbevHm0bVt8H47Y2Fhuu+02zp41byreffddevfuDcAbb7zBl19+iZubG8OHD+f1119n37593HvvvZw8eRJ3d3fmzZvH4cOHmTp1Kj///DMADz74IFFRUUyYMIGIiAhuuukmFi9ezBNPPEFKSso5v5+fnx/Hjx/n3nvv5cCBAwBMnz6dX3/9laCgICZNmgTAM888Q2hoKI+UaGRS00OOUsod+Au4HIgDNgBjtNY7SzteXqeElXLycnBTbmW+Cc/JyyHmWAyrDq2ilmctbmh/A4E+gYCZOrb84HI+3vQx8SnxnM06S2pWKnW869C7cW96N+5Np/qdOJ1+msNJhzmcfJjEjERSs1JJzUrl+Nnj7Du9j/2n95OZm0ldn7r0aNSDHo16EOIXUnA+Hw8fRrYeSWSDyFJHgVIyU4hPiedM+hlC/EIIrRVKHe86xY7Nzctl8YHFzIyZyU97fio1gHm6edKsbjMCfQIJ8A7A38uflKwUTqefJiEtgbjkOHJ1bqnPU6PajWhXrx3tQtqRnp3O+iPr2XFiB7k6l0CfQC4Nv5QejXqQlp3G3tN72Xd6HwlpCWTnZZOTl0N2bjaZuZkF661KU79WfSICI7is2WVc1foqejTqgbubOzl5OcQlx7Hz5E7Wxq1lXfw6Nh/djEbj4+GDr4cv/l7+BPgEEOgTSKBPIKF+oYTWCsXX05c52+bw5+E/qe1VGz9PP46fPU7jOo25rdNtNKrTiFqetfD38ie8Tjgtg1oS7BdMTl4Oa+PWsmjfItYfWU8d7zo09G9ovmoXXrord3ad2sWOEzvYf2Y/TQOa0qVhF7o06ELTwKbF/rvTWpOek05SRhJJmUkFa9BSMlMK/ptJyUohOTO54MvP068gzDaq04gb299Y5vN3PrImp6ZRCgYNMl87d8LLL5t9drSGavwJtnCASZMgJsa+54yMhGnTyrw5KCiIHj16sHDhQq6++mrmzp3LjTfeiFKKV199laCgIHJzcxk8eDBbt26lU6dOpZ5n48aNzJ07l5iYGHJycujatSvdunUD4Nprr+Wuu+4C4Nlnn+WTTz7hoYceYtSoUaWO5GRkZDBhwgR+//13Wrduzbhx45g+fXpBMAgJCWHTpk28//77TJ06lY8//rjY/UNDQ1m8eDE+Pj7s3buXMWPGEB0dzcKFC/nxxx9Zt24dfn5+nD59GoCxY8fy5JNPMnr0aDIyMsjLy+Pw4cPlPq3BwcFs2rQJgISEhFJ/v4cffpgBAwbwww8/kJubS2pqKmFhYVx77bVMmjSJvLw85s6dy/r168t9rBqqB7BPa30AQCk1F7gaKDXkCGGl0kYgSt4eFRZFVNi57/2UUgyMGMjAiIHnfZxe4WV3Y83NyyUhPYF6fvUqtd6mtndt2nqXv3Gru5s7w1oOY1jLYeTm5XIo6RB7T+9l/+n91PWtS8fQjrQObo2ne9mzUzJzMvkr4S92nNzBoaRDZoRJa7JysziQeIBdJ3cxM2YmXu5edA/rzqjWowivE87GoxtZfXg1v+77FS93L1oEtaBlUEsuDb8UTzdPPNw88HDzwNvDG293b7w9vPHz9MPXwxdfT1+yc7M5nHyYw0mH2Z2wmzf/fJN/rfoXIX4h1PGuw6GkQwXhyE250TG0I6PajMLL3YuMnAzSc9JJyUwhKTOJ/af3cybjDCfOniArNwuAZoHNeGvoW0zsMhFfD19+2vMTH278kNdWvVbq81DXpy65OpfkzGTclBud6nfiYOJBftv/G8mZyaXeR6EIqx3G0dSjBaN0YEbcfDx8cFfupGSllBvyit7HFkLTstM4lXaKXJ1L04CmFxVyKktCjiu45BL46it4/nl4913TwEAIi40ZM4a5c+cWhJxPPvkEgG+++YYZM2aQk5PD0aNH2blzZ5khZ+XKlYwePRq//CYbo0aNKrht+/btPPvssyQmJpKamlps/U9p9uzZQ7NmzWjdujUA48eP57333isIOdfm/3/TrVs3vv/+3EXF2dnZPPjgg8TExODu7s5ff/0FwJIlS7j99tsLagwKCiIlJYX4+HhGjx4NgI+PT4Wes5tuuum8v98ff/zBrFmzAHB3dy8YtQoODmbz5s0cP36cLl26EBwcXKHHrGEaAUWTZhzQ06JahKjy3N3cndohzt3NnWZ1m9GsbjNoUfH7eXt407F+RzrW71jmMbaZS6WFtbTsNLzdvS96GlhiRiK/7vuVX/b+QnZeNje3v5lmdZvRKqgV3cK64e/lf95zaK1JzkzmdPppmgQ0KVbTdZdcx3WXXEdadhopmSmczT5LSmZKQTDcm7AXjWZI8yEMbjaYur51i/2OR1OOcjT1KEdTjpKVm0W7eu1oG9IWP08/0rPT2XZiG5uPbuZY6jHSc9LJyMkgNy+3oElGHe86ZjQtf+SpjncdanvVLpjmWHLantbajPiUMm3RGSTkuJJ27eC996yuQlQ15Yy4ONLVV1/No48+yqZNm0hLS6Nbt278/fffTJ06lQ0bNlC3bl0mTJhARsa5UxMqYsKECcyfP5//b+/+Y6u6yziOvx9Ku0IhMBzBygWGUCEEuLQrgtTAWCWBuYBLXGnRuAzJsszEaTRm+o8xZH8YiAyiWbJstEjIVOZSmXEkBiH6j4RNgs6CkU22QVaGKKWxSwf08Y9zuOfetpfxo9zDPefzSgg9517a5z552ofnnu/5NpvN0tHRwaFDh24p3rvuCn44V1RUcPny0Hestm3bxpQpUzh27BgDAwPXPbjkGz16NAMD0Ttlg197TU1N7uMbfX2bNm2io6OD7u5uNm7ceMOxScDMHgceB5g+fXrM0YjISLnWlaj8e6RuxcTqibTOb6V1futNfw4zY0L1hGvutDe2cmxBzNlPZj/2846tHMusSbOYNWn46XFM5ZjcksSRYmbcPebugmGrlK7vbisRkRs0btw4Vq5cycaNG2lrawPg4sWL1NTUMGHCBM6ePctrr712zc+xfPlyOjs7+fDDD+nt7eXVV1/NPdbb20ttbS2XLl1iz549ufPjx4+nt3fou0Zz5szh1KlTnDx5EoDdu3ezYsWK6349PT091NbWMmrUKHbv3s2VK8H671WrVtHe3k5fXx8Q3I80fvx4MpkMnZ2dAPT399PX18eMGTPo6uqiv7+fCxcucODAgaJfr9jra25uzu1Qd+XKFXp6egB4+OGH2b9/P0eOHPnYq1opdgaYlnecCc/luPvz7t7o7o2TJ08uaXAiIjJyNOSIyG3T1tbGsWPHckNONpulvr6euXPnsmHDBpqamq757xsaGli/fj3ZbJY1a9awePHi3GObN29myZIlNDU1FWwS0NraypYtW6ivr+ett97Kna+urqa9vZ1HHnmEBQsWMGrUKJ544onrfi1PPvkku3btIpvNcuLEidxVl9WrV7N27VoaGxtZtGgRW7duBYIhaseOHSxcuJBly5bR3d3NtGnTaGlpYf78+bS0tFBfX1/06xV7fdu3b+fgwYMsWLCA++67j65w2/iqqipWrlxJS0vLbdmZLSGOAHVmNtPMqoBWYF/MMYmIyG2g3dVEEiju3dWk9AYGBmhoaGDv3r3U1dUN+5y0764GYGYPAs8SbCG9092fKfZc9SkRkfjdbJ/SlRwRkTLX1dXF7NmzaW5uLjrgSMDdf+fun3H3WdcacEREpLxp4wERkTI3b9683O/NEREREV3JERERERGRhNGQI5JQcd1vJ3cm1YOIiKSJhhyRBKqurub8+fP6j60AwYBz/vz5m/rdPiIiIuVI9+SIJFAmk+H06dOcO3cu7lDkDlFdXU0mk4k7DBERkZLQkCOSQJWVlcycOTPuMERERERioeVqIiIiIiKSKBpyREREREQkUTTkiIiIiIhIolhcuy+Z2TngnVv4FPcA/x6hcMqdclFI+YgoFxHlIpKfixnuPjnOYO5U6lMjTvmIKBcR5SKiXBS6mo+b6lOxDTm3ysxed/fGuOO4EygXhZSPiHIRUS4iykVpKM+FlI+IchFRLiLKRaFbzYeWq4mIiIiISKJoyBERERERkUQp5yHn+bgDuIMoF4WUj4hyEVEuIspFaSjPhZSPiHIRUS4iykWhW8pH2d6TIyIiIiIiMpxyvpIjIiIiIiIyRFkOOWa22sz+YWYnzezpuOMpJTObZmYHzazLzP5uZk+F5yeZ2e/N7J/h33fHHWupmFmFmR01s9+GxzPN7HBYH780s6q4YywFM5toZi+b2QkzO25mn0t5XXw7/B5508xeMrPqtNSGme00sw/M7M28c8PWggV2hDn5q5k1xBd5cqhPqU/lU5+KqFdF1Kdub58quyHHzCqAnwFrgHlAm5nNizeqkroMfMfd5wFLgW+Er/9p4IC71wEHwuO0eAo4nnf8Y2Cbu88G/gt8PZaoSm87sN/d5wJZgpyksi7MbCrwTaDR3ecDFUAr6amNDmD1oHPFamENUBf+eRx4rkQxJpb6lPrUMNSnIupVqE9Rgj5VdkMO8FngpLu/7e4fAb8A1sUcU8m4+/vu/pfw416CHw5TCXKwK3zaLuBLsQRYYmaWAb4IvBAeG/AA8HL4lFTkwswmAMuBFwHc/SN3v0BK6yI0GhhjZqOBscD7pKQ23P2PwH8GnS5WC+uAn3vgz8BEM6stSaDJpT6lPpWjPhVRrxpCfarQiPapchxypgLv5R2fDs+ljpndC9QDh4Ep7v5++FA3MCWuuErsWeB7wEB4/AnggrtfDo/TUh8zgXNAe7gk4gUzqyGldeHuZ4CtwLsETaMHeIN01sZVxWpBP1NHnnIaUp8C1KfyqVeF1KeGNaJ9qhyHHAHMbBzwa+Bb7n4x/zEPtsxL/LZ5ZvYQ8IG7vxF3LHeA0UAD8Jy71wP/Y9Dl/rTUBUC4jncdQUP9FFDD0MviqZWmWpD4qE+pTw1DvSqkPnVtI1EH5TjknAGm5R1nwnOpYWaVBI1jj7u/Ep4+e/XSXfj3B3HFV0JNwFozO0WwHOQBgrW+E8NLv5Ce+jgNnHb3w+HxywSNJI11AfAF4F/ufs7dLwGvENRLGmvjqmK1kPqfqbdB6nOqPpWjPlVIvSqiPjXUiPapchxyjgB14e4TVQQ3ae2LOaaSCdfyvggcd/ef5D20D3g0/PhR4Deljq3U3P377p5x93sJ6uAP7v4V4CDw5fBpaclFN/Cemc0JTzUDXaSwLkLvAkvNbGz4PXM1H6mrjTzFamEf8LVw95qlQE/ecgG5OepT6lOA+tRg6lUF1KeGGtE+VZa/DNTMHiRY41oB7HT3Z+KNqHTM7PPAn4C/Ea3v/QHBeudfAdOBd4AWdx98Q1dimdn9wHfd/SEz+zTBO2aTgKPAV929P8bwSsLMFhHc2FoFvA08RvBGRirrwsx+BKwn2OnpKLCJYA1v4mvDzF4C7gfuAc4CPwQ6GaYWwub6U4JlEn3AY+7+egxhJ4r6lPrUYOpTAfWqiPrU7e1TZTnkiIiIiIiIFFOOy9VERERERESK0pAjIiIiIiKJoiFHREREREQSRUOOiIiIiIgkioYcERERERFJFA05IiIiIiKSKBpyREREREQkUTTkiIiIiIhIovwfr801f5YGr6IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['accuracy']\n",
    "    val_acc = hist['val_accuracy']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    f, ax = plt.subplots(1,2, figsize=(14,6))\n",
    "    ax[0].plot(epochs, acc, 'g', label='Training accuracy')\n",
    "    ax[0].plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    ax[0].set_title('Training and validation accuracy')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(epochs, loss, 'g', label='Training loss')\n",
    "    ax[1].plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    ax[1].set_title('Training and validation loss')\n",
    "    ax[1].legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_accuracy_and_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9f38ef29-5f7a-4799-bf97-9f19d26eab79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run model - predict validation set\n",
      "Last validation loss: 0.2989058494567871, accuracy: 0.9365384578704834\n"
     ]
    }
   ],
   "source": [
    "print(\"run model - predict validation set\")\n",
    "score = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'Last validation loss: {score[0]}, accuracy: {score[1]}')\n",
    "# load saved optimal model\n",
    "# model_optimal = model\n",
    "# model_optimal.load_weights(checkpointer.model.weights)\n",
    "# score = model_optimal.evaluate(X_val, y_val, verbose=0)\n",
    "# print(f'Best validation loss: {score[0]}, accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2351d5e2-c6fc-4469-be09-552a7e53e875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_show_classes(model, X_val, y_val):\n",
    "    #get the predictions for the test data\n",
    "    predicted_classes = model.predict_classes(X_val)\n",
    "    #get the indices to be plotted\n",
    "    y_true = np.argmax(y_val,axis=1)\n",
    "    correct = np.nonzero(predicted_classes==y_true)[0]\n",
    "    incorrect = np.nonzero(predicted_classes!=y_true)[0]\n",
    "    print(\"Correct predicted classes:\",correct.shape[0])\n",
    "    print(\"Incorrect predicted classes:\",incorrect.shape[0])\n",
    "    target_names = [\"Class {}:\".format(i) for i in range(NUM_CLASSES)]\n",
    "    print(classification_report(y_true, predicted_classes, target_names=target_names))\n",
    "    return correct, incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "528e4dd7-3767-4ab0-85be-ff18cab6e0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0912f884-9616-42f3-b063-a34a9d01e4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predicted classes: 4870\n",
      "Incorrect predicted classes: 330\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Class 0:       0.93      0.97      0.95       518\n",
      "    Class 1:       0.90      0.98      0.94       578\n",
      "    Class 2:       0.92      0.90      0.91       492\n",
      "    Class 3:       0.97      0.92      0.95       533\n",
      "    Class 4:       0.93      0.96      0.94       543\n",
      "    Class 5:       0.95      0.94      0.95       451\n",
      "    Class 6:       0.92      0.97      0.94       524\n",
      "    Class 7:       0.93      0.97      0.95       562\n",
      "    Class 8:       0.97      0.91      0.94       467\n",
      "    Class 9:       0.98      0.84      0.90       532\n",
      "\n",
      "    accuracy                           0.94      5200\n",
      "   macro avg       0.94      0.94      0.94      5200\n",
      "weighted avg       0.94      0.94      0.94      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct, incorrect = predict_show_classes(model, X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
